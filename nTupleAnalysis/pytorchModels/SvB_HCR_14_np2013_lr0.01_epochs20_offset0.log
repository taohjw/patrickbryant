0 >> Epoch <<   Data Set |  Loss %(zz, zh, tt, mj) | σ     | σ(SR) | % AUC | % AUC | AUC Bar Graph ^ (ABC, Max Loss, chi2/bin, p-value) * Output Model
0 >>  1/20 <<   Training | 0.7171 (21, 24, 11, 35) | 0.684 | 0.820 | 87.01 | 87.15 |-------------------------------|
0             Validation | 0.7219 (22, 23, 11, 34) | 0.694 | 0.834 | 86.89 | 87.03 |##############################| ^ (0.4%, 16.26, 2.5, 0%) 
setGhostBatches(16)
Increase training batch size: 1024 -> 2048 (1096 batches)
0 >>  2/20 <<   Training | 0.6758 (24, 26, 12, 29) | 0.782 | 0.937 | 87.85 | 88.46 |--------------------------------------------|
0             Validation | 0.6818 (24, 25, 12, 28) | 0.752 | 0.904 | 87.62 | 88.34 |###########################################| ^ (0.4%, 15.89, 2.4, 0%) 
0 >>  3/20 <<   Training | 0.6760 (25, 24, 12, 29) | 0.762 | 0.916 | 87.80 | 88.56 |---------------------------------------------|
0             Validation | 0.6830 (26, 24, 12, 29) | 0.760 | 0.912 | 87.42 | 88.41 |############################################| ^ (0.4%, 16.11, 1.8, 1%) 
setGhostBatches(4)
Increase training batch size: 2048 -> 4096 (548 batches)
0 >>  4/20 <<   Training | 0.6665 (24, 26, 12, 29) | 0.815 | 0.974 | 88.20 | 88.79 |-----------------------------------------------|
0             Validation | 0.6741 (25, 25, 12, 28) | 0.783 | 0.940 | 87.85 | 88.62 |##############################################| ^ (0.5%, 15.59, 2.1, 0%) 
0 >>  5/20 <<   Training | 0.6651 (24, 26, 13, 28) | 0.833 | 0.996 | 88.25 | 88.83 |------------------------------------------------|
0             Validation | 0.6728 (25, 25, 12, 27) | 0.786 | 0.943 | 87.94 | 88.65 |##############################################| ^ (0.5%, 15.46, 1.9, 1%) 
0 >>  6/20 <<   Training | 0.6654 (25, 25, 13, 28) | 0.837 | 1.002 | 88.30 | 88.80 |------------------------------------------------|
0             Validation | 0.6739 (26, 25, 12, 27) | 0.790 | 0.946 | 87.92 | 88.59 |#############################################| ^ (0.6%, 13.44, 2.6, 0%) 
setGhostBatches(1)
Increase training batch size: 4096 -> 8192 (274 batches)
0 >>  7/20 <<   Training | 0.6627 (22, 25, 12, 31) | 0.832 | 0.994 | 88.62 | 88.89 |------------------------------------------------|
0             Validation | 0.6712 (24, 25, 12, 30) | 0.787 | 0.942 | 88.18 | 88.68 |##############################################| ^ (0.6%, 15.09, 2.6, 0%) 
0 >>  8/20 <<   Training | 0.6618 (22, 25, 12, 32) | 0.833 | 0.996 | 88.80 | 88.97 |-------------------------------------------------|
0             Validation | 0.6705 (23, 24, 12, 31) | 0.795 | 0.953 | 88.30 | 88.73 |###############################################| ^ (0.6%, 15.08, 1.9, 1%) 
0 >>  9/20 <<   Training | 0.6611 (25, 27, 12, 27) | 0.843 | 1.006 | 88.57 | 88.99 |-------------------------------------------------|
0             Validation | 0.6712 (26, 26, 12, 26) | 0.809 | 0.971 | 88.07 | 88.73 |###############################################| ^ (0.7%, 14.67, 2.3, 0%) 
0 >> 10/20 <<   Training | 0.6626 (23, 28, 13, 27) | 0.827 | 0.990 | 88.45 | 88.93 |-------------------------------------------------|
0             Validation | 0.6718 (24, 28, 12, 27) | 0.794 | 0.952 | 87.96 | 88.69 |##############################################| ^ (0.6%, 13.81, 2.0, 0%) 
setGhostBatches(0)
Increase training batch size: 8192 -> 16384 (137 batches)
0 >> 11/20 <<   Training | 0.6614 (23, 29, 12, 26) | 0.853 | 1.020 | 88.44 | 89.00 |--------------------------------------------------|
0             Validation | 0.6719 (25, 28, 12, 26) | 0.820 | 0.980 | 87.89 | 88.72 |###############################################| ^ (0.7%, 14.64, 1.9, 1%) 
0 >> 12/20 <<   Training | 0.6586 (24, 26, 13, 28) | 0.847 | 1.011 | 88.64 | 89.05 |--------------------------------------------------|
0             Validation | 0.6693 (25, 25, 12, 27) | 0.811 | 0.970 | 88.02 | 88.76 |###############################################| ^ (0.7%, 13.38, 1.8, 1%) 
0 >> 13/20 <<   Training | 0.6600 (26, 26, 12, 26) | 0.853 | 1.018 | 88.60 | 89.00 |-------------------------------------------------|
0             Validation | 0.6719 (27, 26, 12, 26) | 0.809 | 0.967 | 88.01 | 88.69 |##############################################| ^ (0.8%, 14.46, 1.8, 1%) 
0 >> 14/20 <<   Training | 0.6587 (24, 28, 13, 26) | 0.858 | 1.026 | 88.67 | 89.08 |--------------------------------------------------|
0             Validation | 0.6703 (26, 27, 12, 25) | 0.823 | 0.985 | 88.05 | 88.79 |###############################################| ^ (0.8%, 16.12, 2.7, 0%) 
0 >> 15/20 <<   Training | 0.6599 (23, 23, 13, 31) | 0.843 | 1.008 | 88.78 | 89.05 |--------------------------------------------------|
0             Validation | 0.6719 (24, 23, 12, 31) | 0.816 | 0.979 | 88.14 | 88.70 |###############################################| ^ (0.9%, 13.60, 2.6, 0%) 
Decay learning rate: 0.010000 -> 0.002500
0 >> 16/20 <<   Training | 0.6553 (23, 27, 13, 28) | 0.856 | 1.024 | 88.88 | 89.15 |---------------------------------------------------|
0             Validation | 0.6669 (24, 27, 12, 27) | 0.820 | 0.981 | 88.23 | 88.83 |################################################| ^ (0.8%, 14.07, 2.2, 0%) 
Decay learning rate: 0.002500 -> 0.000625
0 >> 17/20 <<   Training | 0.6543 (23, 26, 12, 29) | 0.856 | 1.023 | 88.94 | 89.17 |---------------------------------------------------|
0             Validation | 0.6661 (25, 26, 12, 28) | 0.824 | 0.988 | 88.30 | 88.84 |################################################| ^ (0.8%, 13.78, 2.5, 0%) 
Decay learning rate: 0.000625 -> 0.000156
0 >> 18/20 <<   Training | 0.6542 (23, 26, 12, 28) | 0.859 | 1.026 | 88.92 | 89.17 |---------------------------------------------------|
0             Validation | 0.6662 (25, 26, 12, 28) | 0.828 | 0.992 | 88.27 | 88.84 |################################################| ^ (0.9%, 13.85, 2.2, 0%) 
Decay learning rate: 0.000156 -> 0.000039
0 >> 19/20 <<   Training | 0.6542 (23, 26, 12, 28) | 0.859 | 1.026 | 88.92 | 89.17 |---------------------------------------------------|
0             Validation | 0.6662 (25, 26, 12, 28) | 0.827 | 0.991 | 88.27 | 88.84 |################################################| ^ (0.9%, 13.86, 2.2, 0%) 
Decay learning rate: 0.000039 -> 0.000010
0 >> 20/20 <<   Training | 0.6542 (23, 26, 12, 29) | 0.859 | 1.026 | 88.92 | 89.17 |---------------------------------------------------|
0             Validation | 0.6662 (25, 26, 12, 28) | 0.827 | 0.990 | 88.27 | 88.84 |################################################| ^ (0.9%, 13.85, 2.3, 0%) * ZZ4b/nTupleAnalysis/pytorchModels/SvB_HCR_14_np2013_lr0.01_epochs20_offset0_epoch20.pkl
Decay learning rate: 0.000010 -> 0.000002
0 >> Epoch <<   Data Set |  Loss %(zz, zh, tt, mj) | σ     | σ(SR) | % AUC | % AUC | AUC Bar Graph ^ (ABC, Max Loss, chi2/bin, p-value) * Output Model
0 >>  1/20 <<   Training | 0.6962 (25, 27, 12, 27) | 0.734 | 0.886 | 86.99 | 87.82 |--------------------------------------|
0             Validation | 0.6953 (24, 27, 12, 28) | 0.738 | 0.886 | 86.45 | 87.74 |#####################################| ^ (0.3%, 11.97, 1.7, 2%) 
setGhostBatches(16)
Increase training batch size: 1024 -> 2048 (1096 batches)
0 >>  2/20 <<   Training | 0.6775 (25, 24, 12, 30) | 0.780 | 0.939 | 87.88 | 88.69 |----------------------------------------------|
0             Validation | 0.6767 (24, 24, 12, 30) | 0.790 | 0.944 | 87.60 | 88.56 |#############################################| ^ (0.4%, 16.47, 2.3, 0%) 
0 >>  3/20 <<   Training | 0.6748 (24, 23, 12, 31) | 0.809 | 0.970 | 87.60 | 88.81 |------------------------------------------------|
0             Validation | 0.6746 (24, 24, 12, 31) | 0.809 | 0.968 | 87.22 | 88.73 |###############################################| ^ (0.3%, 13.06, 1.7, 2%) 
setGhostBatches(4)
Increase training batch size: 2048 -> 4096 (548 batches)
0 >>  4/20 <<   Training | 0.6681 (23, 25, 12, 30) | 0.808 | 0.969 | 88.42 | 88.87 |------------------------------------------------|
0             Validation | 0.6684 (23, 26, 12, 30) | 0.832 | 0.995 | 87.99 | 88.77 |###############################################| ^ (0.3%, 15.18, 1.7, 2%) 
0 >>  5/20 <<   Training | 0.6712 (24, 24, 12, 30) | 0.801 | 0.961 | 88.13 | 88.74 |-----------------------------------------------|
0             Validation | 0.6723 (24, 24, 12, 30) | 0.804 | 0.959 | 87.60 | 88.62 |##############################################| ^ (0.3%, 17.30, 2.7, 0%) 
0 >>  6/20 <<   Training | 0.6686 (21, 25, 12, 32) | 0.814 | 0.977 | 88.59 | 88.84 |------------------------------------------------|
0             Validation | 0.6712 (22, 25, 12, 32) | 0.824 | 0.984 | 88.00 | 88.69 |##############################################| ^ (0.4%, 16.59, 2.0, 0%) 
setGhostBatches(1)
Increase training batch size: 4096 -> 8192 (274 batches)
0 >>  7/20 <<   Training | 0.6616 (23, 26, 12, 29) | 0.821 | 0.984 | 88.59 | 89.02 |--------------------------------------------------|
0             Validation | 0.6637 (23, 26, 12, 29) | 0.828 | 0.989 | 87.96 | 88.88 |################################################| ^ (0.4%, 15.19, 2.1, 0%) 
0 >>  8/20 <<   Training | 0.6616 (24, 26, 12, 29) | 0.820 | 0.984 | 88.61 | 89.04 |--------------------------------------------------|
0             Validation | 0.6641 (24, 26, 12, 29) | 0.823 | 0.983 | 87.98 | 88.88 |################################################| ^ (0.5%, 17.95, 1.9, 1%) 
0 >>  9/20 <<   Training | 0.6616 (25, 26, 12, 27) | 0.835 | 1.004 | 88.67 | 89.03 |--------------------------------------------------|
0             Validation | 0.6635 (25, 26, 12, 27) | 0.854 | 1.021 | 88.10 | 88.88 |################################################| ^ (0.5%, 17.13, 2.0, 0%) 
0 >> 10/20 <<   Training | 0.6612 (25, 25, 12, 28) | 0.826 | 0.991 | 88.58 | 89.05 |--------------------------------------------------|
0             Validation | 0.6637 (25, 25, 12, 28) | 0.843 | 1.006 | 87.99 | 88.90 |################################################| ^ (0.4%, 16.21, 2.0, 0%) 
setGhostBatches(0)
Increase training batch size: 8192 -> 16384 (137 batches)
0 >> 11/20 <<   Training | 0.6607 (22, 28, 12, 28) | 0.822 | 0.988 | 88.69 | 89.09 |--------------------------------------------------|
0             Validation | 0.6637 (22, 28, 12, 28) | 0.832 | 0.992 | 88.02 | 88.92 |#################################################| ^ (0.5%, 16.14, 2.2, 0%) 
0 >> 12/20 <<   Training | 0.6594 (24, 27, 13, 27) | 0.835 | 1.002 | 88.76 | 89.11 |---------------------------------------------------|
0             Validation | 0.6623 (24, 27, 12, 27) | 0.848 | 1.012 | 88.08 | 88.94 |#################################################| ^ (0.5%, 15.50, 2.3, 0%) 
0 >> 13/20 <<   Training | 0.6627 (21, 26, 12, 32) | 0.807 | 0.969 | 88.93 | 89.05 |--------------------------------------------------|
0             Validation | 0.6663 (21, 26, 12, 31) | 0.820 | 0.979 | 88.21 | 88.89 |################################################| ^ (0.4%, 16.37, 1.8, 1%) 
0 >> 14/20 <<   Training | 0.6596 (25, 27, 12, 26) | 0.847 | 1.015 | 88.76 | 89.15 |---------------------------------------------------|
0             Validation | 0.6622 (25, 27, 12, 26) | 0.864 | 1.031 | 88.10 | 88.97 |#################################################| ^ (0.5%, 17.12, 1.7, 2%) 
0 >> 15/20 <<   Training | 0.6580 (24, 25, 13, 29) | 0.840 | 1.006 | 88.94 | 89.15 |---------------------------------------------------|
0             Validation | 0.6610 (24, 25, 13, 29) | 0.861 | 1.027 | 88.28 | 88.99 |#################################################| ^ (0.5%, 16.78, 2.6, 0%) 
Decay learning rate: 0.010000 -> 0.002500
0 >> 16/20 <<   Training | 0.6565 (23, 27, 12, 28) | 0.837 | 1.003 | 88.92 | 89.18 |---------------------------------------------------|
0             Validation | 0.6599 (23, 27, 12, 28) | 0.857 | 1.023 | 88.21 | 89.01 |##################################################| ^ (0.5%, 16.24, 2.0, 0%) 
Decay learning rate: 0.002500 -> 0.000625
0 >> 17/20 <<   Training | 0.6558 (23, 26, 13, 28) | 0.850 | 1.019 | 88.93 | 89.21 |----------------------------------------------------|
0             Validation | 0.6593 (24, 26, 12, 28) | 0.869 | 1.038 | 88.23 | 89.03 |##################################################| ^ (0.5%, 16.62, 2.6, 0%) 
Decay learning rate: 0.000625 -> 0.000156
0 >> 18/20 <<   Training | 0.6557 (24, 26, 12, 29) | 0.851 | 1.019 | 88.94 | 89.21 |----------------------------------------------------|
0             Validation | 0.6592 (24, 26, 12, 29) | 0.871 | 1.039 | 88.24 | 89.04 |##################################################| ^ (0.5%, 16.59, 2.5, 0%) 
Decay learning rate: 0.000156 -> 0.000039
0 >> 19/20 <<   Training | 0.6557 (24, 26, 12, 29) | 0.849 | 1.018 | 88.94 | 89.21 |----------------------------------------------------|
0             Validation | 0.6592 (24, 26, 12, 28) | 0.869 | 1.038 | 88.24 | 89.04 |##################################################| ^ (0.5%, 16.58, 2.8, 0%) 
Decay learning rate: 0.000039 -> 0.000010
0 >> 20/20 <<   Training | 0.6557 (23, 26, 12, 29) | 0.848 | 1.018 | 88.94 | 89.21 |----------------------------------------------------|
0             Validation | 0.6592 (24, 26, 12, 28) | 0.870 | 1.038 | 88.24 | 89.04 |##################################################| ^ (0.5%, 16.57, 2.7, 0%) * ZZ4b/nTupleAnalysis/pytorchModels/SvB_HCR_14_np2013_lr0.01_epochs20_offset0_epoch20.pkl
Decay learning rate: 0.000010 -> 0.000002
