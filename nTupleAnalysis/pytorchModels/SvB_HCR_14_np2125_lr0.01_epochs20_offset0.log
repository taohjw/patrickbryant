0 >> Epoch <<   Data Set |  Loss %(zz, zh, tt, mj) | σ     | σ(SR) | % AUC | % AUC | AUC Bar Graph ^ (ABC, Max Loss, chi2/bin, p-value) * Output Model
0 >> Epoch <<   Data Set |  Loss %(zz, zh, tt, mj) | σ     | σ(SR) | % AUC | % AUC | AUC Bar Graph ^ (ABC, Max Loss, chi2/bin, p-value) * Output Model
0 >>  1/20 <<   Training | 0.6990 (24, 29, 12, 25) | 0.696 | 0.838 | 86.43 | 87.84 |--------------------------------------|
0             Validation | 0.7021 (25, 29, 12, 25) | 0.683 | 0.817 | 86.33 | 87.88 |######################################| ^ (0.4%, 10.99, 3.1, 0%) 
setGhostBatches(16)
Increase training batch size: 1024 -> 2048 (1098 batches)
0 >>  2/20 <<   Training | 0.6757 (24, 27, 12, 27) | 0.782 | 0.943 | 87.75 | 88.51 |---------------------------------------------|
0             Validation | 0.6796 (25, 27, 12, 27) | 0.750 | 0.899 | 87.57 | 88.51 |#############################################| ^ (0.3%, 13.74, 3.6, 0%) 
0 >>  3/20 <<   Training | 0.6777 (27, 25, 13, 27) | 0.795 | 0.954 | 87.89 | 88.41 |--------------------------------------------|
0             Validation | 0.6838 (27, 24, 13, 26) | 0.787 | 0.939 | 87.46 | 88.35 |###########################################| ^ (0.4%, 11.82, 4.1, 0%) 
setGhostBatches(4)
Increase training batch size: 2048 -> 4096 (549 batches)
0 >>  4/20 <<   Training | 0.6685 (24, 26, 13, 29) | 0.797 | 0.955 | 88.37 | 88.63 |----------------------------------------------|
0             Validation | 0.6735 (24, 25, 12, 29) | 0.769 | 0.917 | 87.93 | 88.62 |##############################################| ^ (0.3%, 14.78, 3.3, 0%) 
0 >>  5/20 <<   Training | 0.6671 (24, 26, 12, 28) | 0.815 | 0.978 | 88.36 | 88.72 |-----------------------------------------------|
0             Validation | 0.6714 (24, 26, 12, 28) | 0.798 | 0.952 | 88.04 | 88.72 |###############################################| ^ (0.4%, 14.84, 3.3, 0%) 
0 >>  6/20 <<   Training | 0.6681 (21, 26, 13, 30) | 0.797 | 0.958 | 88.45 | 88.75 |-----------------------------------------------|
0             Validation | 0.6716 (22, 26, 13, 30) | 0.768 | 0.918 | 88.22 | 88.75 |###############################################| ^ (0.3%, 14.81, 3.8, 0%) 
setGhostBatches(1)
Increase training batch size: 4096 -> 8192 (274 batches)
0 >>  7/20 <<   Training | 0.6617 (23, 27, 12, 28) | 0.834 | 0.998 | 88.60 | 88.87 |------------------------------------------------|
0             Validation | 0.6676 (24, 27, 12, 28) | 0.809 | 0.965 | 88.11 | 88.83 |################################################| ^ (0.3%, 14.06, 3.4, 0%) 
0 >>  8/20 <<   Training | 0.6629 (22, 28, 12, 28) | 0.824 | 0.988 | 88.59 | 88.91 |-------------------------------------------------|
0             Validation | 0.6689 (23, 28, 12, 28) | 0.794 | 0.949 | 88.14 | 88.84 |################################################| ^ (0.3%, 14.03, 3.5, 0%) 
0 >>  9/20 <<   Training | 0.6621 (25, 25, 13, 28) | 0.822 | 0.985 | 88.47 | 88.89 |------------------------------------------------|
0             Validation | 0.6684 (26, 25, 13, 27) | 0.812 | 0.967 | 88.07 | 88.85 |################################################| ^ (0.3%, 13.72, 3.6, 0%) 
0 >> 10/20 <<   Training | 0.6601 (24, 25, 12, 29) | 0.830 | 0.995 | 88.72 | 88.92 |-------------------------------------------------|
0             Validation | 0.6671 (25, 25, 12, 29) | 0.824 | 0.984 | 88.21 | 88.85 |################################################| ^ (0.3%, 13.69, 4.3, 0%) 
setGhostBatches(0)
Increase training batch size: 8192 -> 16384 (137 batches)
0 >> 11/20 <<   Training | 0.6606 (26, 26, 12, 27) | 0.850 | 1.019 | 88.69 | 88.93 |-------------------------------------------------|
0             Validation | 0.6691 (27, 25, 12, 27) | 0.827 | 0.987 | 88.04 | 88.82 |################################################| ^ (0.3%, 13.97, 3.5, 0%) 
0 >> 12/20 <<   Training | 0.6593 (23, 27, 13, 28) | 0.833 | 0.998 | 88.72 | 88.98 |-------------------------------------------------|
0             Validation | 0.6663 (24, 27, 13, 27) | 0.804 | 0.958 | 88.17 | 88.89 |################################################| ^ (0.4%, 13.60, 3.5, 0%) 
0 >> 13/20 <<   Training | 0.6594 (24, 24, 12, 30) | 0.837 | 1.002 | 88.72 | 88.97 |-------------------------------------------------|
0             Validation | 0.6669 (25, 24, 12, 30) | 0.834 | 0.994 | 88.14 | 88.87 |################################################| ^ (0.3%, 12.37, 3.3, 0%) 
0 >> 14/20 <<   Training | 0.6602 (25, 27, 13, 26) | 0.852 | 1.020 | 88.75 | 88.94 |-------------------------------------------------|
0             Validation | 0.6693 (26, 27, 12, 25) | 0.833 | 0.991 | 88.14 | 88.78 |###############################################| ^ (0.4%, 13.36, 3.9, 0%) 
0 >> 15/20 <<   Training | 0.6576 (23, 26, 13, 28) | 0.841 | 1.007 | 88.83 | 89.01 |--------------------------------------------------|
0             Validation | 0.6652 (24, 26, 13, 28) | 0.821 | 0.979 | 88.30 | 88.92 |#################################################| ^ (0.3%, 13.36, 4.0, 0%) 
Decay learning rate: 0.010000 -> 0.002500
0 >> 16/20 <<   Training | 0.6558 (25, 26, 12, 28) | 0.858 | 1.027 | 88.83 | 89.07 |--------------------------------------------------|
0             Validation | 0.6646 (26, 25, 12, 28) | 0.841 | 1.000 | 88.15 | 88.95 |#################################################| ^ (0.3%, 12.85, 3.4, 0%) 
Decay learning rate: 0.002500 -> 0.000625
0 >> 17/20 <<   Training | 0.6551 (24, 26, 13, 28) | 0.860 | 1.029 | 88.90 | 89.09 |--------------------------------------------------|
0             Validation | 0.6637 (25, 25, 12, 28) | 0.841 | 1.002 | 88.22 | 88.97 |#################################################| ^ (0.3%, 13.22, 2.9, 0%) 
Decay learning rate: 0.000625 -> 0.000156
0 >> 18/20 <<   Training | 0.6549 (23, 26, 12, 29) | 0.862 | 1.031 | 88.93 | 89.09 |--------------------------------------------------|
0             Validation | 0.6633 (24, 26, 12, 28) | 0.837 | 0.998 | 88.27 | 88.98 |#################################################| ^ (0.3%, 13.00, 2.8, 0%) 
Decay learning rate: 0.000156 -> 0.000039
0 >> 19/20 <<   Training | 0.6549 (23, 26, 12, 29) | 0.861 | 1.030 | 88.93 | 89.09 |--------------------------------------------------|
0             Validation | 0.6633 (25, 26, 12, 28) | 0.838 | 0.999 | 88.27 | 88.98 |#################################################| ^ (0.3%, 13.04, 2.9, 0%) 
Decay learning rate: 0.000039 -> 0.000010
0 >> 20/20 <<   Training | 0.6549 (23, 26, 12, 29) | 0.861 | 1.030 | 88.93 | 89.09 |--------------------------------------------------|
0             Validation | 0.6633 (25, 26, 12, 28) | 0.838 | 0.999 | 88.27 | 88.98 |#################################################| ^ (0.3%, 13.04, 2.9, 0%) * ZZ4b/nTupleAnalysis/pytorchModels/SvB_HCR_14_np2125_lr0.01_epochs20_offset0_epoch20.pkl
Decay learning rate: 0.000010 -> 0.000002
0 >> Epoch <<   Data Set |  Loss %(zz, zh, tt, mj) | σ     | σ(SR) | % AUC | % AUC | AUC Bar Graph ^ (ABC, Max Loss, chi2/bin, p-value) * Output Model
0 >>  1/20 <<   Training | 0.7003 (26, 27, 11, 27) | 0.685 | 0.824 | 86.70 | 87.82 |--------------------------------------|
0             Validation | 0.7064 (27, 26, 11, 26) | 0.668 | 0.807 | 86.31 | 87.73 |#####################################| ^ (0.4%, 17.04, 2.8, 0%) 
setGhostBatches(16)
Increase training batch size: 1024 -> 2048 (1096 batches)
0 >>  2/20 <<   Training | 0.6817 (24, 27, 12, 27) | 0.787 | 0.944 | 87.24 | 88.33 |-------------------------------------------|
0             Validation | 0.6888 (25, 27, 12, 26) | 0.765 | 0.917 | 86.89 | 88.17 |#########################################| ^ (0.5%, 18.55, 2.7, 0%) 
0 >>  3/20 <<   Training | 0.6841 (22, 28, 12, 29) | 0.774 | 0.929 | 87.14 | 88.28 |------------------------------------------|
0             Validation | 0.6913 (23, 28, 11, 29) | 0.742 | 0.892 | 86.68 | 88.07 |########################################| ^ (0.6%, 14.75, 1.4, 8%) 
setGhostBatches(4)
Increase training batch size: 2048 -> 4096 (548 batches)
0 >>  4/20 <<   Training | 0.6711 (23, 24, 12, 30) | 0.792 | 0.945 | 88.00 | 88.73 |-----------------------------------------------|
0             Validation | 0.6805 (25, 24, 12, 30) | 0.766 | 0.916 | 87.43 | 88.51 |#############################################| ^ (0.6%, 17.29, 2.0, 0%) 
0 >>  5/20 <<   Training | 0.6683 (26, 25, 12, 27) | 0.789 | 0.947 | 88.20 | 88.81 |------------------------------------------------|
0             Validation | 0.6779 (27, 25, 12, 27) | 0.773 | 0.930 | 87.72 | 88.59 |#############################################| ^ (0.6%, 17.07, 2.6, 0%) 
0 >>  6/20 <<   Training | 0.6646 (23, 24, 13, 31) | 0.829 | 0.993 | 88.60 | 88.91 |-------------------------------------------------|
0             Validation | 0.6743 (24, 24, 12, 31) | 0.786 | 0.939 | 88.04 | 88.64 |##############################################| ^ (0.7%, 15.06, 2.2, 0%) 
setGhostBatches(1)
Increase training batch size: 4096 -> 8192 (274 batches)
0 >>  7/20 <<   Training | 0.6595 (24, 26, 12, 28) | 0.844 | 1.009 | 88.73 | 89.02 |--------------------------------------------------|
0             Validation | 0.6707 (25, 26, 12, 28) | 0.816 | 0.978 | 88.14 | 88.72 |###############################################| ^ (0.8%, 14.85, 2.4, 0%) 
0 >>  8/20 <<   Training | 0.6615 (25, 26, 12, 27) | 0.845 | 1.008 | 88.59 | 88.98 |-------------------------------------------------|
0             Validation | 0.6731 (26, 26, 12, 26) | 0.804 | 0.961 | 87.90 | 88.67 |##############################################| ^ (0.8%, 16.26, 2.2, 0%) 
0 >>  9/20 <<   Training | 0.6597 (23, 28, 12, 27) | 0.842 | 1.006 | 88.68 | 89.02 |--------------------------------------------------|
0             Validation | 0.6715 (25, 27, 12, 27) | 0.797 | 0.956 | 88.01 | 88.70 |##############################################| ^ (0.8%, 14.09, 2.5, 0%) 
0 >> 10/20 <<   Training | 0.6603 (23, 26, 12, 30) | 0.840 | 1.004 | 88.60 | 88.98 |-------------------------------------------------|
0             Validation | 0.6720 (24, 25, 12, 29) | 0.795 | 0.950 | 87.95 | 88.65 |##############################################| ^ (0.8%, 14.05, 2.3, 0%) 
setGhostBatches(0)
Increase training batch size: 8192 -> 16384 (137 batches)
0 >> 11/20 <<   Training | 0.6625 (21, 25, 13, 33) | 0.841 | 1.004 | 88.95 | 89.00 |--------------------------------------------------|
0             Validation | 0.6729 (22, 24, 12, 32) | 0.811 | 0.972 | 88.33 | 88.69 |##############################################| ^ (0.8%, 13.98, 2.4, 0%) 
0 >> 12/20 <<   Training | 0.6568 (23, 25, 13, 30) | 0.852 | 1.019 | 88.89 | 89.11 |---------------------------------------------------|
0             Validation | 0.6682 (24, 25, 12, 29) | 0.820 | 0.982 | 88.28 | 88.78 |###############################################| ^ (0.9%, 14.74, 2.8, 0%) 
0 >> 13/20 <<   Training | 0.6580 (24, 27, 12, 27) | 0.846 | 1.010 | 88.66 | 89.08 |--------------------------------------------------|
0             Validation | 0.6705 (26, 27, 12, 26) | 0.814 | 0.974 | 88.06 | 88.74 |###############################################| ^ (0.9%, 14.83, 2.3, 0%) 
0 >> 14/20 <<   Training | 0.6570 (22, 26, 13, 29) | 0.844 | 1.007 | 88.92 | 89.08 |--------------------------------------------------|
0             Validation | 0.6692 (24, 26, 12, 29) | 0.805 | 0.965 | 88.19 | 88.73 |###############################################| ^ (0.9%, 13.68, 2.4, 0%) 
0 >> 15/20 <<   Training | 0.6609 (26, 25, 12, 27) | 0.830 | 0.992 | 88.66 | 88.98 |-------------------------------------------------|
0             Validation | 0.6747 (28, 25, 12, 26) | 0.801 | 0.959 | 87.93 | 88.61 |##############################################| ^ (0.9%, 14.33, 2.4, 0%) 
Decay learning rate: 0.010000 -> 0.002500
0 >> 16/20 <<   Training | 0.6547 (25, 27, 12, 27) | 0.863 | 1.031 | 88.86 | 89.18 |---------------------------------------------------|
0             Validation | 0.6682 (26, 26, 12, 27) | 0.828 | 0.989 | 88.14 | 88.81 |################################################| ^ (0.9%, 13.63, 2.6, 0%) 
Decay learning rate: 0.002500 -> 0.000625
0 >> 17/20 <<   Training | 0.6538 (24, 26, 12, 29) | 0.867 | 1.035 | 88.93 | 89.19 |---------------------------------------------------|
0             Validation | 0.6671 (25, 25, 12, 28) | 0.826 | 0.987 | 88.19 | 88.81 |################################################| ^ (1.0%, 13.50, 2.7, 0%) 
Decay learning rate: 0.000625 -> 0.000156
0 >> 18/20 <<   Training | 0.6537 (23, 26, 12, 29) | 0.863 | 1.030 | 88.93 | 89.19 |---------------------------------------------------|
0             Validation | 0.6670 (25, 25, 12, 28) | 0.829 | 0.991 | 88.19 | 88.82 |################################################| ^ (1.0%, 13.47, 2.5, 0%) 
Decay learning rate: 0.000156 -> 0.000039
0 >> 19/20 <<   Training | 0.6536 (23, 26, 12, 29) | 0.866 | 1.033 | 88.93 | 89.19 |---------------------------------------------------|
0             Validation | 0.6669 (25, 26, 12, 28) | 0.829 | 0.991 | 88.19 | 88.82 |################################################| ^ (1.0%, 13.47, 2.7, 0%) 
Decay learning rate: 0.000039 -> 0.000010
0 >> 20/20 <<   Training | 0.6536 (23, 26, 12, 29) | 0.865 | 1.033 | 88.93 | 89.19 |---------------------------------------------------|
0             Validation | 0.6669 (25, 26, 12, 28) | 0.829 | 0.991 | 88.19 | 88.82 |################################################| ^ (1.0%, 13.47, 2.8, 0%) * ZZ4b/nTupleAnalysis/pytorchModels/SvB_HCR_14_np2125_lr0.01_epochs20_offset0_epoch20.pkl
Decay learning rate: 0.000010 -> 0.000002
