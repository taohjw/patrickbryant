0 >> Epoch <<   Data Set |  Loss %(zz, zh, tt, mj) | σ     | σ(SR) | % AUC | % AUC | AUC Bar Graph ^ (ABC, Max Loss, chi2/bin, p-value) * Output Model
0 >>  1/20 <<   Training | 0.6611 (26, 23, 12, 29) | 0.808 | 0.980 | 88.46 | 88.87 |------------------------------------------------|
0             Validation | 0.6607 (26, 23, 12, 30) | 0.808 | 0.976 | 88.11 | 88.73 |###############################################| ^ (0.4%, 12.55, 2.2, 0%) 
setGhostBatches(16)
Increase training batch size: 1024 -> 2048 (1096 batches)
0 >>  2/20 <<   Training | 0.6455 (28, 24, 10, 29) | 0.797 | 0.965 | 88.68 | 89.41 |------------------------------------------------------|
0             Validation | 0.6466 (28, 24, 10, 29) | 0.818 | 0.985 | 88.25 | 89.19 |###################################################| ^ (0.6%, 13.82, 1.9, 1%) 
0 >>  3/20 <<   Training | 0.6341 (20, 28,  9, 34) | 0.893 | 1.071 | 89.68 | 89.91 |-----------------------------------------------------------|
0             Validation | 0.6375 (20, 28,  9, 34) | 0.905 | 1.082 | 89.20 | 89.71 |#########################################################| ^ (0.5%, 12.21, 1.7, 2%) 
setGhostBatches(4)
Increase training batch size: 2048 -> 4096 (548 batches)
0 >>  4/20 <<   Training | 0.6143 (25, 26, 12, 27) | 0.960 | 1.149 | 90.22 | 90.24 |--------------------------------------------------------------|
0             Validation | 0.6183 (25, 26, 12, 27) | 0.958 | 1.146 | 89.71 | 89.99 |###########################################################| ^ (0.6%, 14.68, 2.2, 0%) 
0 >>  5/20 <<   Training | 0.6150 (25, 26, 12, 27) | 0.935 | 1.121 | 90.17 | 90.16 |-------------------------------------------------------------|
0             Validation | 0.6193 (25, 26, 12, 27) | 0.935 | 1.112 | 89.77 | 89.85 |##########################################################| ^ (0.8%, 15.39, 1.6, 3%) 
0 >>  6/20 <<   Training | 0.6131 (23, 27, 11, 29) | 0.961 | 1.149 | 90.20 | 90.24 |--------------------------------------------------------------|
0             Validation | 0.6175 (23, 27, 11, 29) | 0.968 | 1.155 | 89.70 | 89.98 |###########################################################| ^ (0.6%, 15.68, 1.6, 3%) 
setGhostBatches(1)
Increase training batch size: 4096 -> 8192 (274 batches)
0 >>  7/20 <<   Training | 0.6065 (23, 27, 11, 30) | 0.970 | 1.161 | 90.58 | 90.41 |----------------------------------------------------------------|
0             Validation | 0.6129 (23, 26, 11, 30) | 0.979 | 1.165 | 90.05 | 90.08 |############################################################| ^ (0.8%, 15.57, 2.3, 0%) 
0 >>  8/20 <<   Training | 0.6093 (23, 25,  9, 32) | 0.981 | 1.174 | 90.55 | 90.43 |----------------------------------------------------------------|
0             Validation | 0.6154 (24, 25,  9, 32) | 0.989 | 1.184 | 89.89 | 90.13 |#############################################################| ^ (0.7%, 14.47, 1.8, 1%) 
0 >>  9/20 <<   Training | 0.6103 (22, 26, 13, 30) | 0.962 | 1.151 | 90.48 | 90.36 |---------------------------------------------------------------|
0             Validation | 0.6167 (22, 26, 12, 29) | 0.968 | 1.154 | 89.86 | 90.05 |############################################################| ^ (0.8%, 16.70, 2.0, 0%) 
0 >> 10/20 <<   Training | 0.6359 (20, 22,  8, 40) | 0.887 | 1.075 | 90.71 | 89.83 |----------------------------------------------------------|
0             Validation | 0.6418 (21, 22,  8, 40) | 0.900 | 1.086 | 90.20 | 89.53 |#######################################################| ^ (0.8%, 16.53, 1.9, 0%) 
setGhostBatches(0)
Increase training batch size: 8192 -> 16384 (137 batches)
0 >> 11/20 <<   Training | 0.6076 (20, 26, 11, 33) | 0.961 | 1.150 | 90.81 | 90.46 |----------------------------------------------------------------|
0             Validation | 0.6145 (21, 26, 11, 33) | 0.950 | 1.136 | 90.12 | 90.13 |#############################################################| ^ (0.8%, 16.31, 1.9, 1%) 
0 >> 12/20 <<   Training | 0.6051 (22, 29, 10, 30) | 0.971 | 1.163 | 90.79 | 90.46 |----------------------------------------------------------------|
0             Validation | 0.6125 (22, 29, 10, 30) | 0.986 | 1.175 | 90.08 | 90.10 |############################################################| ^ (0.9%, 16.05, 2.8, 0%) 
0 >> 13/20 <<   Training | 0.6051 (23, 29, 12, 27) | 0.967 | 1.155 | 90.62 | 90.50 |-----------------------------------------------------------------|
0             Validation | 0.6125 (24, 28, 12, 27) | 0.974 | 1.161 | 89.93 | 90.15 |#############################################################| ^ (0.9%, 15.60, 1.9, 1%) 
0 >> 14/20 <<   Training | 0.6042 (21, 27, 11, 31) | 0.963 | 1.151 | 90.83 | 90.49 |----------------------------------------------------------------|
0             Validation | 0.6119 (22, 27, 11, 30) | 0.987 | 1.179 | 90.06 | 90.12 |#############################################################| ^ (0.9%, 14.31, 1.8, 1%) 
0 >> 15/20 <<   Training | 0.6043 (22, 27, 11, 29) | 0.986 | 1.179 | 90.64 | 90.49 |----------------------------------------------------------------|
0             Validation | 0.6109 (23, 27, 11, 29) | 0.994 | 1.185 | 89.96 | 90.17 |#############################################################| ^ (0.8%, 15.73, 1.7, 1%) 
Decay learning rate: 0.010000 -> 0.002500
0 >> 16/20 <<   Training | 0.5995 (24, 27, 11, 28) | 0.995 | 1.188 | 90.83 | 90.60 |------------------------------------------------------------------|
0             Validation | 0.6076 (25, 26, 11, 28) | 1.015 | 1.213 | 90.11 | 90.24 |##############################################################| ^ (0.9%, 16.23, 1.9, 1%) 
Decay learning rate: 0.002500 -> 0.000625
0 >> 17/20 <<   Training | 0.5989 (24, 27, 11, 29) | 0.993 | 1.186 | 90.86 | 90.62 |------------------------------------------------------------------|
0             Validation | 0.6072 (25, 27, 11, 29) | 1.006 | 1.201 | 90.12 | 90.25 |##############################################################| ^ (0.9%, 16.02, 2.1, 0%) 
Decay learning rate: 0.000625 -> 0.000156
0 >> 18/20 <<   Training | 0.5986 (24, 27, 11, 29) | 0.995 | 1.186 | 90.89 | 90.62 |------------------------------------------------------------------|
0             Validation | 0.6070 (24, 26, 11, 29) | 1.010 | 1.205 | 90.15 | 90.25 |##############################################################| ^ (0.9%, 16.06, 2.6, 0%) 
Decay learning rate: 0.000156 -> 0.000039
0 >> 19/20 <<   Training | 0.5985 (23, 27, 11, 30) | 0.995 | 1.187 | 90.90 | 90.62 |------------------------------------------------------------------|
0             Validation | 0.6070 (24, 26, 11, 29) | 1.012 | 1.208 | 90.16 | 90.25 |##############################################################| ^ (0.9%, 16.06, 2.3, 0%) 
Decay learning rate: 0.000039 -> 0.000010
0 >> 20/20 <<   Training | 0.5985 (23, 27, 11, 30) | 0.994 | 1.186 | 90.90 | 90.62 |------------------------------------------------------------------|
0             Validation | 0.6070 (24, 26, 11, 29) | 1.012 | 1.207 | 90.16 | 90.25 |##############################################################| ^ (0.9%, 16.06, 2.4, 0%) * ZZ4b/nTupleAnalysis/pytorchModels/SvB_MA_HCR+attention_14_np2714_lr0.01_epochs20_offset0_epoch20.pkl
Decay learning rate: 0.000010 -> 0.000002
