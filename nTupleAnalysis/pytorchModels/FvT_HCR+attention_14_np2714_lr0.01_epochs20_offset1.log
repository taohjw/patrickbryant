1 >> Epoch <<   Data Set |  Loss %(d4, d3, t4, t3) | Norm  | r neg | % AUC | % AUC | AUC Bar Graph ^ (ABC, Max Loss, chi2/bin, p-value) * Output Model
1 >>  1/20 <<   Training | 0.9066 (41, 37,  5, 15) | 1.125 | 0.005 | 83.28 | 64.41 |------------------------|
1             Validation | 0.9063 (41, 37,  5, 15) | 1.124 | 0.005 | 83.30 | 64.36 |#######################| ^ (0.7%, 3.62, 2.0, 0%) 
setGhostBatches(16)
Increase training batch size: 1024 -> 2048 (1210 batches)
1 >>  2/20 <<   Training | 0.8883 (34, 41,  6, 16) | 0.840 | 0.000 | 84.95 | 65.61 |------------------------------------|
1             Validation | 0.8884 (34, 41,  6, 16) | 0.840 | 0.000 | 84.92 | 65.56 |###################################| ^ (0.6%, 3.47, 1.8, 1%) 
1 >>  3/20 <<   Training | 0.8889 (42, 33,  6, 16) | 1.209 | 0.001 | 85.39 | 65.99 |---------------------------------------|
1             Validation | 0.8894 (42, 33,  7, 16) | 1.208 | 0.001 | 85.37 | 65.80 |######################################| ^ (1.4%, 3.08, 2.1, 0%) 
setGhostBatches(4)
Increase training batch size: 2048 -> 4096 (605 batches)
1 >>  4/20 <<   Training | 0.8804 (37, 37,  7, 17) | 0.968 | 0.001 | 85.75 | 66.32 |-------------------------------------------|
1             Validation | 0.8809 (37, 37,  7, 17) | 0.968 | 0.000 | 85.76 | 66.13 |#########################################| ^ (1.5%, 3.24, 1.5, 6%) 
1 >>  5/20 <<   Training | 0.8780 (36, 38,  7, 16) | 0.940 | 0.001 | 85.93 | 66.32 |-------------------------------------------|
1             Validation | 0.8788 (36, 38,  7, 16) | 0.939 | 0.001 | 85.91 | 66.09 |########################################| ^ (1.5%, 3.76, 2.6, 0%) 
1 >>  6/20 <<   Training | 0.8853 (35, 38,  7, 18) | 0.943 | 0.001 | 85.87 | 66.11 |-----------------------------------------|
1             Validation | 0.8860 (35, 38,  7, 18) | 0.942 | 0.000 | 85.86 | 65.88 |######################################| ^ (1.5%, 3.10, 1.4, 9%) 
setGhostBatches(1)
Increase training batch size: 4096 -> 8192 (302 batches)
1 >>  7/20 <<   Training | 0.8757 (40, 38,  6, 14) | 1.060 | 0.002 | 86.26 | 66.30 |-------------------------------------------|
1             Validation | 0.8776 (40, 38,  6, 14) | 1.059 | 0.002 | 86.19 | 65.93 |#######################################| ^ (2.4%, 4.00, 1.5, 6%) 
1 >>  8/20 <<   Training | 0.8740 (40, 37,  6, 15) | 1.061 | 0.001 | 86.21 | 66.54 |---------------------------------------------|
1             Validation | 0.8755 (40, 37,  6, 15) | 1.059 | 0.000 | 86.18 | 66.19 |#########################################| ^ (2.2%, 3.77, 1.4, 8%) 
1 >>  9/20 <<   Training | 0.8743 (36, 39,  6, 17) | 0.902 | 0.001 | 86.36 | 66.74 |-----------------------------------------------|
1             Validation | 0.8766 (36, 39,  6, 16) | 0.901 | 0.001 | 86.27 | 66.34 |###########################################| ^ (2.5%, 4.46, 0.9, 58%) 
1 >> 10/20 <<   Training | 0.8749 (40, 38,  6, 14) | 1.046 | 0.000 | 86.27 | 66.22 |------------------------------------------|
1             Validation | 0.8773 (40, 38,  6, 14) | 1.044 | 0.000 | 86.24 | 65.74 |#####################################| ^ (3.0%, 4.09, 1.6, 3%) 
setGhostBatches(0)
Increase training batch size: 8192 -> 16384 (151 batches)
1 >> 11/20 <<   Training | 0.8724 (40, 37,  6, 15) | 1.074 | 0.001 | 86.43 | 66.47 |--------------------------------------------|
1             Validation | 0.8747 (40, 37,  6, 15) | 1.073 | 0.001 | 86.36 | 66.01 |########################################| ^ (2.8%, 4.36, 1.4, 9%) 
1 >> 12/20 <<   Training | 0.8711 (37, 39,  6, 15) | 0.988 | 0.001 | 86.44 | 66.73 |-----------------------------------------------|
1             Validation | 0.8735 (37, 39,  6, 15) | 0.986 | 0.001 | 86.37 | 66.23 |##########################################| ^ (3.0%, 3.96, 2.0, 0%) 
1 >> 13/20 <<   Training | 0.8710 (39, 38,  6, 15) | 1.058 | 0.001 | 86.44 | 66.77 |-----------------------------------------------|
1             Validation | 0.8737 (39, 38,  6, 15) | 1.057 | 0.001 | 86.36 | 66.23 |##########################################| ^ (3.2%, 3.81, 1.5, 4%) 
1 >> 14/20 <<   Training | 0.8703 (37, 39,  6, 15) | 0.967 | 0.000 | 86.45 | 66.80 |-----------------------------------------------|
1             Validation | 0.8732 (37, 39,  6, 15) | 0.966 | 0.000 | 86.36 | 66.28 |##########################################| ^ (3.1%, 3.55, 1.0, 45%) 
1 >> 15/20 <<   Training | 0.8705 (38, 37,  7, 15) | 1.004 | 0.000 | 86.44 | 66.80 |------------------------------------------------|
1             Validation | 0.8736 (39, 37,  7, 15) | 1.003 | 0.000 | 86.37 | 66.28 |##########################################| ^ (3.1%, 4.18, 1.0, 34%) 
Decay learning rate: 0.010000 -> 0.002500
1 >> 16/20 <<   Training | 0.8689 (39, 37,  6, 15) | 1.046 | 0.001 | 86.56 | 66.97 |-------------------------------------------------|
1             Validation | 0.8723 (39, 37,  6, 15) | 1.045 | 0.001 | 86.46 | 66.40 |############################################| ^ (3.4%, 3.98, 1.2, 21%) 
Decay learning rate: 0.002500 -> 0.000625
1 >> 17/20 <<   Training | 0.8684 (38, 38,  6, 15) | 1.011 | 0.001 | 86.58 | 67.04 |--------------------------------------------------|
1             Validation | 0.8717 (38, 38,  6, 15) | 1.010 | 0.000 | 86.48 | 66.47 |############################################| ^ (3.3%, 3.85, 1.8, 1%) 
Decay learning rate: 0.000625 -> 0.000156
1 >> 18/20 <<   Training | 0.8684 (38, 38,  6, 15) | 0.995 | 0.001 | 86.58 | 66.99 |-------------------------------------------------|
1             Validation | 0.8717 (38, 38,  6, 15) | 0.994 | 0.001 | 86.48 | 66.41 |############################################| ^ (3.4%, 3.85, 1.8, 1%) 
Decay learning rate: 0.000156 -> 0.000039
1 >> 19/20 <<   Training | 0.8684 (38, 38,  6, 15) | 1.004 | 0.001 | 86.58 | 67.00 |-------------------------------------------------|
1             Validation | 0.8717 (38, 38,  6, 15) | 1.002 | 0.001 | 86.48 | 66.42 |############################################| ^ (3.4%, 3.86, 1.8, 1%) 
Decay learning rate: 0.000039 -> 0.000010
1 >> 20/20 <<   Training | 0.8684 (38, 38,  6, 15) | 1.002 | 0.001 | 86.58 | 67.00 |--------------------------------------------------|
1             Validation | 0.8717 (38, 38,  6, 15) | 1.001 | 0.001 | 86.48 | 66.43 |############################################| ^ (3.4%, 3.85, 1.8, 1%) * ZZ4b/nTupleAnalysis/pytorchModels/FvT_HCR+attention_14_np2714_lr0.01_epochs20_offset1_epoch20.pkl
Decay learning rate: 0.000010 -> 0.000002
