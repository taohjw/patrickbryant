1 >> Epoch <<   Data Set |  Loss %(d4, d3, t4, t3) | Norm  | r neg | % AUC | % AUC | AUC Bar Graph ^ (ABC, Max Loss, chi2/bin, p-value) * Output Model
1 >>  1/20 <<   Training | 0.8863 (40, 35,  7, 18) | 1.090 | 0.000 | 83.49 | 63.82 |------------------|
1             Validation | 0.8858 (40, 35,  7, 18) | 1.089 | 0.000 | 83.59 | 63.81 |##################| ^ (0.7%, 2.76, 1.3, 13%) 
setGhostBatches(16)
Increase training batch size: 1024 -> 2048 (1210 batches)
1 >>  2/20 <<   Training | 0.8679 (38, 40,  6, 16) | 0.959 | 0.001 | 84.66 | 66.02 |----------------------------------------|
1             Validation | 0.8681 (38, 40,  6, 16) | 0.959 | 0.001 | 84.69 | 65.97 |#######################################| ^ (0.7%, 3.23, 1.4, 8%) 
1 >>  3/20 <<   Training | 0.8698 (40, 41,  6, 13) | 0.994 | 0.001 | 85.44 | 64.98 |-----------------------------|
1             Validation | 0.8699 (40, 41,  6, 13) | 0.993 | 0.001 | 85.47 | 64.92 |#############################| ^ (0.7%, 3.67, 1.6, 3%) 
setGhostBatches(4)
Increase training batch size: 2048 -> 4096 (605 batches)
1 >>  4/20 <<   Training | 0.8625 (42, 38,  6, 14) | 1.128 | 0.003 | 85.73 | 66.13 |-----------------------------------------|
1             Validation | 0.8628 (42, 38,  6, 14) | 1.126 | 0.003 | 85.76 | 65.99 |#######################################| ^ (1.0%, 4.64, 1.4, 10%) 
1 >>  5/20 <<   Training | 0.8584 (37, 40,  7, 16) | 0.906 | 0.001 | 85.84 | 66.29 |------------------------------------------|
1             Validation | 0.8589 (37, 40,  7, 16) | 0.906 | 0.001 | 85.86 | 66.16 |#########################################| ^ (1.1%, 3.74, 2.1, 0%) 
1 >>  6/20 <<   Training | 0.8574 (39, 37,  7, 16) | 1.011 | 0.000 | 86.00 | 66.50 |---------------------------------------------|
1             Validation | 0.8582 (40, 37,  7, 16) | 1.011 | 0.000 | 86.00 | 66.31 |###########################################| ^ (1.3%, 3.11, 1.9, 0%) 
setGhostBatches(1)
Increase training batch size: 4096 -> 8192 (302 batches)
1 >>  7/20 <<   Training | 0.8543 (40, 39,  6, 15) | 1.021 | 0.002 | 86.14 | 66.45 |--------------------------------------------|
1             Validation | 0.8556 (40, 39,  6, 15) | 1.021 | 0.002 | 86.13 | 66.16 |#########################################| ^ (1.9%, 4.70, 2.1, 0%) 
1 >>  8/20 <<   Training | 0.8548 (41, 38,  6, 15) | 1.075 | 0.001 | 86.19 | 66.37 |-------------------------------------------|
1             Validation | 0.8565 (41, 38,  6, 15) | 1.074 | 0.001 | 86.19 | 66.00 |#######################################| ^ (2.3%, 4.38, 1.0, 38%) 
1 >>  9/20 <<   Training | 0.8549 (39, 39,  6, 15) | 0.971 | 0.000 | 86.18 | 66.46 |--------------------------------------------|
1             Validation | 0.8568 (40, 39,  6, 15) | 0.971 | 0.000 | 86.16 | 66.10 |########################################| ^ (2.3%, 3.70, 1.1, 31%) 
1 >> 10/20 <<   Training | 0.8536 (37, 39,  7, 17) | 0.951 | 0.001 | 86.23 | 66.85 |------------------------------------------------|
1             Validation | 0.8556 (38, 39,  7, 17) | 0.950 | 0.001 | 86.19 | 66.49 |############################################| ^ (2.2%, 4.10, 2.1, 0%) 
setGhostBatches(0)
Increase training batch size: 8192 -> 16384 (151 batches)
1 >> 11/20 <<   Training | 0.8529 (38, 39,  6, 16) | 0.981 | 0.001 | 86.23 | 66.88 |------------------------------------------------|
1             Validation | 0.8549 (38, 39,  6, 16) | 0.980 | 0.001 | 86.17 | 66.50 |#############################################| ^ (2.3%, 4.05, 1.6, 3%) 
1 >> 12/20 <<   Training | 0.8520 (38, 39,  7, 16) | 0.959 | 0.001 | 86.28 | 66.94 |-------------------------------------------------|
1             Validation | 0.8542 (38, 39,  7, 16) | 0.959 | 0.001 | 86.24 | 66.55 |#############################################| ^ (2.4%, 3.19, 1.2, 18%) 
1 >> 13/20 <<   Training | 0.8523 (39, 40,  6, 15) | 0.981 | 0.002 | 86.26 | 66.82 |------------------------------------------------|
1             Validation | 0.8552 (39, 40,  6, 15) | 0.980 | 0.002 | 86.19 | 66.33 |###########################################| ^ (3.0%, 4.26, 1.2, 23%) 
1 >> 14/20 <<   Training | 0.8515 (41, 37,  6, 15) | 1.081 | 0.001 | 86.33 | 66.88 |------------------------------------------------|
1             Validation | 0.8542 (41, 37,  6, 15) | 1.080 | 0.001 | 86.27 | 66.37 |###########################################| ^ (3.1%, 4.01, 1.6, 3%) 
1 >> 15/20 <<   Training | 0.8515 (37, 41,  7, 16) | 0.912 | 0.001 | 86.34 | 66.81 |------------------------------------------------|
1             Validation | 0.8548 (37, 41,  7, 15) | 0.912 | 0.001 | 86.27 | 66.27 |##########################################| ^ (3.2%, 4.47, 1.5, 6%) 
Decay learning rate: 0.010000 -> 0.002500
1 >> 16/20 <<   Training | 0.8494 (38, 40,  6, 16) | 0.958 | 0.001 | 86.42 | 67.09 |--------------------------------------------------|
1             Validation | 0.8527 (38, 40,  6, 16) | 0.958 | 0.001 | 86.36 | 66.54 |#############################################| ^ (3.3%, 4.35, 1.5, 5%) 
Decay learning rate: 0.002500 -> 0.000625
1 >> 17/20 <<   Training | 0.8489 (38, 40,  6, 16) | 0.975 | 0.001 | 86.44 | 67.11 |---------------------------------------------------|
1             Validation | 0.8523 (39, 39,  6, 16) | 0.975 | 0.001 | 86.37 | 66.53 |#############################################| ^ (3.5%, 4.17, 1.0, 45%) 
Decay learning rate: 0.000625 -> 0.000156
1 >> 18/20 <<   Training | 0.8488 (39, 39,  6, 16) | 0.993 | 0.001 | 86.45 | 67.10 |---------------------------------------------------|
1             Validation | 0.8522 (39, 39,  6, 16) | 0.993 | 0.001 | 86.39 | 66.51 |#############################################| ^ (3.5%, 4.12, 0.9, 51%) 
Decay learning rate: 0.000156 -> 0.000039
1 >> 19/20 <<   Training | 0.8488 (39, 39,  6, 16) | 0.996 | 0.001 | 86.45 | 67.11 |---------------------------------------------------|
1             Validation | 0.8522 (39, 39,  6, 16) | 0.995 | 0.001 | 86.39 | 66.52 |#############################################| ^ (3.5%, 4.13, 1.0, 38%) 
Decay learning rate: 0.000039 -> 0.000010
1 >> 20/20 <<   Training | 0.8488 (39, 39,  6, 16) | 0.998 | 0.001 | 86.45 | 67.11 |---------------------------------------------------|
1             Validation | 0.8522 (39, 39,  6, 16) | 0.998 | 0.001 | 86.39 | 66.52 |#############################################| ^ (3.5%, 4.13, 1.0, 34%) * ZZ4b/nTupleAnalysis/pytorchModels/FvT_HCR_keep_lr_high+attention_14_np2826_lr0.01_epochs20_offset1_epoch20.pkl
Decay learning rate: 0.000010 -> 0.000002
