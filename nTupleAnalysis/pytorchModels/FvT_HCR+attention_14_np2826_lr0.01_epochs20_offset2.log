2 >> Epoch <<   Data Set |  Loss %(d4, d3, t4, t3) | Norm  | r neg | % AUC | % AUC | AUC Bar Graph ^ (ABC, Max Loss, chi2/bin, p-value) * Output Model
2 >>  1/20 <<   Training | 0.8788 (43, 35,  6, 16) | 1.196 | 0.004 | 83.79 | 65.53 |-----------------------------------|
2             Validation | 0.8786 (43, 35,  6, 16) | 1.189 | 0.004 | 83.77 | 65.52 |###################################| ^ (1.0%, 5.96, 1.6, 3%) 
setGhostBatches(16)
Increase training batch size: 1024 -> 2048 (1210 batches)
2 >>  2/20 <<   Training | 0.8662 (38, 37,  7, 18) | 0.959 | 0.002 | 85.37 | 66.07 |----------------------------------------|
2             Validation | 0.8672 (38, 38,  7, 18) | 0.953 | 0.002 | 85.31 | 65.96 |#######################################| ^ (1.0%, 4.04, 2.0, 0%) 
2 >>  3/20 <<   Training | 0.8636 (38, 39,  7, 17) | 0.906 | 0.001 | 85.60 | 66.25 |------------------------------------------|
2             Validation | 0.8651 (38, 39,  6, 17) | 0.899 | 0.001 | 85.55 | 66.09 |########################################| ^ (1.1%, 3.10, 1.6, 4%) 
setGhostBatches(4)
Increase training batch size: 2048 -> 4096 (605 batches)
2 >>  4/20 <<   Training | 0.8701 (42, 39,  5, 13) | 1.093 | 0.005 | 85.61 | 65.94 |---------------------------------------|
2             Validation | 0.8717 (42, 39,  5, 13) | 1.086 | 0.005 | 85.53 | 65.70 |#####################################| ^ (1.5%, 4.35, 1.4, 8%) 
2 >>  5/20 <<   Training | 0.8600 (38, 41,  6, 15) | 0.909 | 0.001 | 86.05 | 65.55 |-----------------------------------|
2             Validation | 0.8622 (38, 41,  6, 15) | 0.902 | 0.001 | 85.99 | 65.29 |################################| ^ (1.7%, 4.54, 1.7, 2%) 
2 >>  6/20 <<   Training | 0.8563 (37, 40,  6, 17) | 0.948 | 0.002 | 86.13 | 66.40 |-------------------------------------------|
2             Validation | 0.8588 (37, 40,  6, 17) | 0.942 | 0.002 | 86.04 | 66.07 |########################################| ^ (2.0%, 4.86, 2.0, 0%) 
setGhostBatches(1)
Increase training batch size: 4096 -> 8192 (302 batches)
2 >>  7/20 <<   Training | 0.8561 (39, 41,  6, 15) | 0.938 | 0.002 | 86.27 | 66.06 |----------------------------------------|
2             Validation | 0.8591 (39, 41,  6, 15) | 0.932 | 0.002 | 86.16 | 65.72 |#####################################| ^ (2.1%, 4.36, 1.3, 15%) 
2 >>  8/20 <<   Training | 0.8533 (40, 39,  6, 15) | 0.996 | 0.004 | 86.23 | 66.60 |---------------------------------------------|
2             Validation | 0.8566 (40, 39,  6, 15) | 0.989 | 0.004 | 86.13 | 66.17 |#########################################| ^ (2.6%, 5.17, 1.2, 19%) 
2 >>  9/20 <<   Training | 0.8524 (41, 37,  6, 16) | 1.082 | 0.001 | 86.33 | 66.82 |------------------------------------------------|
2             Validation | 0.8555 (41, 37,  6, 16) | 1.075 | 0.001 | 86.21 | 66.38 |###########################################| ^ (2.6%, 4.16, 1.4, 7%) 
2 >> 10/20 <<   Training | 0.8516 (39, 38,  6, 16) | 1.009 | 0.001 | 86.41 | 66.92 |-------------------------------------------------|
2             Validation | 0.8552 (39, 38,  6, 16) | 1.003 | 0.001 | 86.29 | 66.41 |############################################| ^ (3.0%, 4.75, 2.0, 0%) 
setGhostBatches(0)
Increase training batch size: 8192 -> 16384 (151 batches)
2 >> 11/20 <<   Training | 0.8539 (39, 40,  6, 16) | 1.008 | 0.001 | 86.36 | 66.92 |-------------------------------------------------|
2             Validation | 0.8572 (39, 40,  6, 16) | 1.001 | 0.001 | 86.25 | 66.44 |############################################| ^ (2.8%, 4.60, 1.4, 8%) 
2 >> 12/20 <<   Training | 0.8514 (42, 37,  7, 15) | 1.098 | 0.000 | 86.45 | 66.99 |-------------------------------------------------|
2             Validation | 0.8552 (42, 36,  7, 15) | 1.090 | 0.000 | 86.33 | 66.44 |############################################| ^ (3.3%, 5.03, 1.8, 1%) 
2 >> 13/20 <<   Training | 0.8510 (40, 38,  7, 15) | 1.023 | 0.000 | 86.39 | 66.84 |------------------------------------------------|
2             Validation | 0.8548 (40, 38,  7, 15) | 1.016 | 0.000 | 86.24 | 66.32 |###########################################| ^ (3.1%, 5.39, 1.1, 28%) 
2 >> 14/20 <<   Training | 0.8498 (40, 38,  6, 15) | 1.046 | 0.001 | 86.45 | 66.89 |------------------------------------------------|
2             Validation | 0.8537 (40, 38,  6, 15) | 1.039 | 0.001 | 86.31 | 66.35 |###########################################| ^ (3.2%, 5.58, 2.0, 0%) 
2 >> 15/20 <<   Training | 0.8516 (39, 38,  6, 17) | 1.014 | 0.001 | 86.42 | 66.97 |-------------------------------------------------|
2             Validation | 0.8554 (39, 38,  6, 17) | 1.007 | 0.001 | 86.27 | 66.42 |############################################| ^ (3.3%, 5.13, 1.5, 4%) 
Decay learning rate: 0.010000 -> 0.002500
2 >> 16/20 <<   Training | 0.8484 (39, 39,  6, 15) | 1.019 | 0.001 | 86.57 | 66.99 |-------------------------------------------------|
2             Validation | 0.8526 (39, 39,  6, 15) | 1.012 | 0.001 | 86.42 | 66.38 |###########################################| ^ (3.6%, 5.52, 2.1, 0%) 
Decay learning rate: 0.002500 -> 0.000625
2 >> 17/20 <<   Training | 0.8478 (39, 39,  6, 16) | 1.004 | 0.001 | 86.59 | 67.11 |---------------------------------------------------|
2             Validation | 0.8522 (39, 39,  6, 16) | 0.997 | 0.001 | 86.44 | 66.50 |#############################################| ^ (3.6%, 5.26, 1.9, 1%) 
Decay learning rate: 0.000625 -> 0.000156
2 >> 18/20 <<   Training | 0.8478 (39, 39,  6, 16) | 1.003 | 0.001 | 86.59 | 67.10 |--------------------------------------------------|
2             Validation | 0.8522 (39, 39,  6, 16) | 0.995 | 0.001 | 86.44 | 66.48 |############################################| ^ (3.6%, 5.39, 2.4, 0%) 
Decay learning rate: 0.000156 -> 0.000039
2 >> 19/20 <<   Training | 0.8477 (39, 39,  6, 16) | 1.001 | 0.001 | 86.59 | 67.08 |--------------------------------------------------|
2             Validation | 0.8522 (39, 39,  6, 16) | 0.994 | 0.001 | 86.44 | 66.46 |############################################| ^ (3.6%, 5.42, 2.3, 0%) 
Decay learning rate: 0.000039 -> 0.000010
2 >> 20/20 <<   Training | 0.8477 (39, 39,  6, 16) | 1.000 | 0.001 | 86.59 | 67.08 |--------------------------------------------------|
2             Validation | 0.8522 (39, 39,  6, 16) | 0.993 | 0.001 | 86.44 | 66.46 |############################################| ^ (3.6%, 5.43, 2.3, 0%) * ZZ4b/nTupleAnalysis/pytorchModels/FvT_HCR_keep_lr_high+attention_14_np2826_lr0.01_epochs20_offset2_epoch20.pkl
Decay learning rate: 0.000010 -> 0.000002
