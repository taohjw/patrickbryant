0 >> Epoch <<   Data Set |  Loss %(d4, d3, t4, t3) | Norm  | r neg | % AUC | % AUC | AUC Bar Graph ^ (ABC, Max Loss, chi2/bin, p-value) * Output Model
0 >>  1/20 <<   Training | 0.8964 (40, 37,  6, 14) | 1.098 | 0.004 | 84.23 | 64.96 |-----------------------------|
0             Validation | 0.8987 (40, 37,  6, 14) | 1.105 | 0.004 | 84.09 | 64.71 |###########################| ^ (1.7%, 4.57, 1.1, 29%) 
setGhostBatches(16)
Increase training batch size: 1024 -> 2048 (1210 batches)
0 >>  2/20 <<   Training | 0.8895 (37, 40,  6, 15) | 0.938 | 0.001 | 84.68 | 64.95 |-----------------------------|
0             Validation | 0.8919 (37, 40,  6, 15) | 0.943 | 0.001 | 84.55 | 64.59 |#########################| ^ (2.5%, 3.68, 2.0, 0%) 
0 >>  3/20 <<   Training | 0.8875 (40, 34,  7, 17) | 1.110 | 0.001 | 85.38 | 65.96 |---------------------------------------|
0             Validation | 0.8901 (40, 34,  7, 17) | 1.116 | 0.001 | 85.24 | 65.63 |####################################| ^ (2.1%, 4.72, 1.6, 3%) 
setGhostBatches(4)
Increase training batch size: 2048 -> 4096 (605 batches)
0 >>  4/20 <<   Training | 0.8777 (38, 37,  7, 16) | 0.991 | 0.001 | 85.85 | 66.40 |-------------------------------------------|
0             Validation | 0.8808 (38, 37,  7, 16) | 0.996 | 0.001 | 85.71 | 65.99 |#######################################| ^ (2.5%, 4.28, 2.0, 0%) 
0 >>  5/20 <<   Training | 0.8748 (39, 38,  6, 15) | 1.028 | 0.001 | 86.15 | 66.38 |-------------------------------------------|
0             Validation | 0.8780 (39, 38,  6, 15) | 1.035 | 0.001 | 86.01 | 65.97 |#######################################| ^ (2.5%, 3.94, 1.7, 2%) 
0 >>  6/20 <<   Training | 0.8769 (36, 39,  6, 16) | 0.948 | 0.002 | 86.14 | 66.42 |--------------------------------------------|
0             Validation | 0.8802 (36, 39,  6, 16) | 0.954 | 0.002 | 85.97 | 65.97 |#######################################| ^ (2.7%, 4.42, 1.4, 7%) 
setGhostBatches(1)
Increase training batch size: 4096 -> 8192 (302 batches)
0 >>  7/20 <<   Training | 0.8742 (35, 39,  6, 17) | 0.917 | 0.001 | 86.33 | 66.66 |----------------------------------------------|
0             Validation | 0.8775 (36, 39,  7, 17) | 0.922 | 0.001 | 86.17 | 66.20 |#########################################| ^ (2.8%, 3.78, 2.0, 0%) 
0 >>  8/20 <<   Training | 0.8733 (40, 37,  6, 15) | 1.074 | 0.001 | 86.29 | 66.74 |-----------------------------------------------|
0             Validation | 0.8773 (41, 37,  6, 15) | 1.080 | 0.001 | 86.13 | 66.25 |##########################################| ^ (2.9%, 3.83, 1.7, 2%) 
0 >>  9/20 <<   Training | 0.8718 (37, 40,  6, 15) | 0.927 | 0.001 | 86.39 | 66.60 |---------------------------------------------|
0             Validation | 0.8759 (37, 40,  6, 15) | 0.932 | 0.001 | 86.22 | 66.10 |#########################################| ^ (3.0%, 4.47, 1.8, 1%) 
0 >> 10/20 <<   Training | 0.8715 (39, 37,  6, 15) | 1.042 | 0.001 | 86.38 | 66.54 |---------------------------------------------|
0             Validation | 0.8760 (39, 37,  6, 15) | 1.048 | 0.001 | 86.18 | 66.01 |########################################| ^ (3.2%, 3.72, 2.2, 0%) 
setGhostBatches(0)
Increase training batch size: 8192 -> 16384 (151 batches)
0 >> 11/20 <<   Training | 0.8717 (38, 38,  6, 16) | 1.013 | 0.001 | 86.41 | 66.84 |------------------------------------------------|
0             Validation | 0.8754 (38, 38,  6, 16) | 1.019 | 0.001 | 86.24 | 66.31 |###########################################| ^ (3.1%, 4.21, 1.6, 4%) 
0 >> 12/20 <<   Training | 0.8699 (39, 38,  6, 15) | 1.023 | 0.001 | 86.51 | 66.72 |-----------------------------------------------|
0             Validation | 0.8744 (39, 38,  6, 14) | 1.029 | 0.001 | 86.32 | 66.17 |#########################################| ^ (3.3%, 3.51, 2.2, 0%) 
0 >> 13/20 <<   Training | 0.8711 (35, 40,  6, 16) | 0.914 | 0.001 | 86.54 | 66.83 |------------------------------------------------|
0             Validation | 0.8751 (36, 40,  6, 16) | 0.920 | 0.001 | 86.36 | 66.31 |###########################################| ^ (3.1%, 3.88, 1.7, 2%) 
0 >> 14/20 <<   Training | 0.8714 (35, 40,  6, 16) | 0.902 | 0.001 | 86.48 | 66.72 |-----------------------------------------------|
0             Validation | 0.8756 (36, 39,  6, 16) | 0.907 | 0.001 | 86.31 | 66.18 |#########################################| ^ (3.2%, 3.91, 1.7, 2%) 
0 >> 15/20 <<   Training | 0.8716 (40, 37,  6, 14) | 1.072 | 0.001 | 86.54 | 66.46 |--------------------------------------------|
0             Validation | 0.8768 (41, 37,  6, 14) | 1.079 | 0.001 | 86.35 | 65.88 |######################################| ^ (3.6%, 3.96, 1.8, 1%) 
Decay learning rate: 0.010000 -> 0.002500
0 >> 16/20 <<   Training | 0.8678 (38, 38,  6, 15) | 1.014 | 0.001 | 86.62 | 66.95 |-------------------------------------------------|
0             Validation | 0.8729 (39, 38,  6, 15) | 1.020 | 0.001 | 86.43 | 66.37 |###########################################| ^ (3.5%, 4.33, 1.9, 0%) 
Decay learning rate: 0.002500 -> 0.000625
0 >> 17/20 <<   Training | 0.8678 (38, 38,  6, 16) | 1.000 | 0.001 | 86.64 | 67.07 |--------------------------------------------------|
0             Validation | 0.8726 (38, 38,  6, 16) | 1.006 | 0.001 | 86.45 | 66.48 |############################################| ^ (3.4%, 4.03, 2.5, 0%) 
Decay learning rate: 0.000625 -> 0.000156
0 >> 18/20 <<   Training | 0.8675 (38, 38,  6, 15) | 1.004 | 0.001 | 86.64 | 67.02 |--------------------------------------------------|
0             Validation | 0.8725 (39, 38,  6, 15) | 1.010 | 0.001 | 86.45 | 66.42 |############################################| ^ (3.5%, 4.06, 2.2, 0%) 
Decay learning rate: 0.000156 -> 0.000039
0 >> 19/20 <<   Training | 0.8675 (38, 38,  6, 15) | 1.001 | 0.001 | 86.64 | 67.02 |--------------------------------------------------|
0             Validation | 0.8725 (38, 38,  6, 15) | 1.006 | 0.001 | 86.45 | 66.43 |############################################| ^ (3.5%, 4.04, 2.3, 0%) 
Decay learning rate: 0.000039 -> 0.000010
0 >> 20/20 <<   Training | 0.8675 (38, 38,  6, 15) | 1.000 | 0.001 | 86.64 | 67.02 |--------------------------------------------------|
0             Validation | 0.8725 (38, 38,  6, 15) | 1.005 | 0.001 | 86.45 | 66.43 |############################################| ^ (3.5%, 4.04, 2.3, 0%) * ZZ4b/nTupleAnalysis/pytorchModels/FvT_HCR+attention_14_np2714_lr0.01_epochs20_offset0_epoch20.pkl
Decay learning rate: 0.000010 -> 0.000002
