0 >> Epoch <<   Data Set |  Loss %(d4, d3, t4, t3) | Norm  | r neg | % AUC | % AUC | AUC Bar Graph ^ (ABC, Max Loss, chi2/bin, p-value) * Output Model
0 >>  1/20 <<   Training | 0.8781 (38, 40,  6, 16) | 0.983 | 0.001 | 83.75 | 65.15 |-------------------------------|
0             Validation | 0.8798 (38, 39,  6, 16) | 0.989 | 0.001 | 83.65 | 64.83 |############################| ^ (2.1%, 3.34, 2.5, 0%) 
setGhostBatches(16)
Increase training batch size: 1024 -> 2048 (1210 batches)
0 >>  2/20 <<   Training | 0.8671 (39, 39,  6, 15) | 0.963 | 0.001 | 84.75 | 66.12 |-----------------------------------------|
0             Validation | 0.8694 (39, 39,  7, 15) | 0.969 | 0.001 | 84.62 | 65.86 |######################################| ^ (1.6%, 3.39, 1.2, 21%) 
0 >>  3/20 <<   Training | 0.8659 (40, 39,  6, 15) | 0.992 | 0.001 | 85.19 | 65.27 |--------------------------------|
0             Validation | 0.8690 (40, 39,  6, 15) | 0.999 | 0.001 | 85.00 | 64.91 |#############################| ^ (2.4%, 3.31, 1.7, 1%) 
setGhostBatches(4)
Increase training batch size: 2048 -> 4096 (605 batches)
0 >>  4/20 <<   Training | 0.8573 (39, 39,  6, 16) | 1.005 | 0.001 | 85.80 | 66.46 |--------------------------------------------|
0             Validation | 0.8603 (40, 38,  6, 16) | 1.012 | 0.001 | 85.64 | 66.08 |########################################| ^ (2.3%, 3.06, 2.4, 0%) 
0 >>  5/20 <<   Training | 0.8570 (39, 38,  6, 16) | 0.982 | 0.000 | 85.86 | 66.53 |---------------------------------------------|
0             Validation | 0.8603 (39, 38,  7, 16) | 0.988 | 0.000 | 85.66 | 66.10 |#########################################| ^ (2.6%, 3.33, 1.9, 0%) 
0 >>  6/20 <<   Training | 0.8592 (42, 38,  6, 14) | 1.094 | 0.002 | 85.98 | 66.19 |-----------------------------------------|
0             Validation | 0.8631 (43, 37,  6, 14) | 1.100 | 0.002 | 85.82 | 65.77 |#####################################| ^ (2.6%, 3.88, 2.1, 0%) 
setGhostBatches(1)
Increase training batch size: 4096 -> 8192 (302 batches)
0 >>  7/20 <<   Training | 0.8549 (39, 40,  6, 14) | 0.981 | 0.001 | 86.17 | 66.18 |-----------------------------------------|
0             Validation | 0.8590 (40, 40,  6, 14) | 0.987 | 0.001 | 85.99 | 65.70 |####################################| ^ (3.0%, 3.66, 1.3, 11%) 
0 >>  8/20 <<   Training | 0.8533 (39, 39,  6, 16) | 1.001 | 0.001 | 86.23 | 66.37 |-------------------------------------------|
0             Validation | 0.8573 (39, 38,  6, 16) | 1.007 | 0.001 | 86.04 | 65.85 |######################################| ^ (3.2%, 3.66, 2.5, 0%) 
0 >>  9/20 <<   Training | 0.8530 (39, 38,  7, 16) | 1.027 | 0.000 | 86.25 | 66.79 |-----------------------------------------------|
0             Validation | 0.8574 (40, 37,  7, 16) | 1.033 | 0.000 | 86.06 | 66.22 |##########################################| ^ (3.4%, 3.74, 2.0, 0%) 
0 >> 10/20 <<   Training | 0.8519 (39, 39,  6, 15) | 1.003 | 0.001 | 86.31 | 66.72 |-----------------------------------------------|
0             Validation | 0.8563 (40, 39,  6, 15) | 1.009 | 0.001 | 86.13 | 66.16 |#########################################| ^ (3.4%, 3.80, 1.7, 2%) 
setGhostBatches(0)
Increase training batch size: 8192 -> 16384 (151 batches)
0 >> 11/20 <<   Training | 0.8518 (37, 41,  6, 16) | 0.904 | 0.001 | 86.32 | 66.88 |------------------------------------------------|
0             Validation | 0.8561 (37, 41,  6, 16) | 0.909 | 0.001 | 86.14 | 66.31 |###########################################| ^ (3.4%, 3.51, 2.3, 0%) 
0 >> 12/20 <<   Training | 0.8538 (36, 43,  6, 15) | 0.880 | 0.001 | 86.39 | 66.74 |-----------------------------------------------|
0             Validation | 0.8582 (37, 43,  6, 15) | 0.885 | 0.001 | 86.19 | 66.12 |#########################################| ^ (3.7%, 3.12, 1.7, 2%) 
0 >> 13/20 <<   Training | 0.8507 (39, 38,  6, 16) | 1.027 | 0.001 | 86.40 | 66.81 |------------------------------------------------|
0             Validation | 0.8555 (40, 38,  6, 16) | 1.032 | 0.001 | 86.20 | 66.15 |#########################################| ^ (3.9%, 4.05, 2.5, 0%) 
0 >> 14/20 <<   Training | 0.8525 (42, 36,  6, 15) | 1.128 | 0.001 | 86.41 | 66.74 |-----------------------------------------------|
0             Validation | 0.8575 (42, 36,  7, 15) | 1.134 | 0.001 | 86.22 | 66.05 |########################################| ^ (4.1%, 3.85, 1.7, 2%) 
0 >> 15/20 <<   Training | 0.8511 (41, 38,  6, 15) | 1.077 | 0.000 | 86.43 | 67.00 |--------------------------------------------------|
0             Validation | 0.8559 (41, 37,  6, 15) | 1.082 | 0.000 | 86.23 | 66.35 |###########################################| ^ (3.8%, 3.41, 1.6, 3%) 
Decay learning rate: 0.010000 -> 0.002500
0 >> 16/20 <<   Training | 0.8492 (40, 39,  6, 15) | 1.029 | 0.001 | 86.51 | 67.07 |--------------------------------------------------|
0             Validation | 0.8547 (40, 38,  6, 15) | 1.034 | 0.001 | 86.31 | 66.37 |###########################################| ^ (4.0%, 3.66, 2.4, 0%) 
Decay learning rate: 0.002500 -> 0.000625
0 >> 17/20 <<   Training | 0.8484 (38, 40,  6, 16) | 0.982 | 0.001 | 86.54 | 67.04 |--------------------------------------------------|
0             Validation | 0.8537 (39, 39,  6, 16) | 0.988 | 0.001 | 86.33 | 66.32 |###########################################| ^ (4.2%, 3.77, 2.7, 0%) 
Decay learning rate: 0.000625 -> 0.000156
0 >> 18/20 <<   Training | 0.8483 (39, 39,  6, 16) | 0.989 | 0.001 | 86.54 | 67.03 |--------------------------------------------------|
0             Validation | 0.8537 (39, 39,  6, 16) | 0.995 | 0.001 | 86.34 | 66.31 |###########################################| ^ (4.2%, 3.76, 2.6, 0%) 
Decay learning rate: 0.000156 -> 0.000039
0 >> 19/20 <<   Training | 0.8483 (39, 39,  6, 16) | 0.997 | 0.001 | 86.54 | 67.05 |--------------------------------------------------|
0             Validation | 0.8536 (39, 39,  6, 16) | 1.002 | 0.001 | 86.34 | 66.33 |###########################################| ^ (4.2%, 3.75, 2.5, 0%) 
Decay learning rate: 0.000039 -> 0.000010
0 >> 20/20 <<   Training | 0.8483 (39, 39,  6, 16) | 0.999 | 0.001 | 86.54 | 67.05 |--------------------------------------------------|
0             Validation | 0.8536 (39, 39,  6, 16) | 1.005 | 0.001 | 86.34 | 66.32 |###########################################| ^ (4.3%, 3.75, 2.6, 0%) * ZZ4b/nTupleAnalysis/pytorchModels/FvT_HCR_keep_lr_high+attention_14_np2826_lr0.01_epochs20_offset0_epoch20.pkl
Decay learning rate: 0.000010 -> 0.000002
