2 >> Epoch <<   Data Set |  Loss %(d4, d3, t4, t3) | Norm  | rchi2 | % AUC | % AUC | AUC Bar Graph ^ (ABC, Max Loss, chi2/bin, p-value) * Output Model
2 >> Epoch <<   Data Set |  Loss %(d4, d3, t4, t3) | Norm  | rchi2 | % AUC | % AUC | AUC Bar Graph ^ (ABC, Max Loss, chi2/bin, p-value) * Output Model
2 >>  1/20 <<   Training | 0.9485 (22, 30,  6, 17) | 0.994 | 641.076 | 83.47 | 68.24 |--------------------------------------------------------------|
2             Validation | 0.9475 (22, 30,  6, 17) | 0.994 | 322.243 | 83.50 | 68.37 |###############################################################| ^ (1.0%, 2.95, 1.2, 22%) 2 >> Epoch <<   Data Set |  Loss %(d4, d3, t4, t3) | Norm  | rchi2 | % AUC | % AUC | AUC Bar Graph ^ (ABC, Max Loss, chi2/bin, p-value) * Output Model
2 >>  1/20 <<   Training | 0.9485 (22, 30,  6, 17) | 0.994 | 3.371 | 83.47 | 68.24 |--------------------------------------------------------------|
2             Validation | 0.9475 (22, 30,  6, 17) | 0.994 | 2.136 | 83.50 | 68.37 |###############################################################| ^ (1.0%, 2.95, 1.2, 22%) 
setGhostBatches(16)
Change training batch size: 1024 -> 2048 (1269 batches)
2 >>  2/20 <<   Training | 0.9410 (22, 26,  7, 20) | 0.985 | 9.603 | 84.03 | 68.27 |--------------------------------------------------------------|
2             Validation | 0.9401 (22, 26,  7, 20) | 0.985 | 5.521 | 84.03 | 68.32 |###############################################################| ^ (0.8%, 3.29, 2.7, 0%) 
2 >>  3/20 <<   Training | 0.9354 (22, 29,  7, 18) | 1.019 | 3.118 | 84.24 | 69.98 |-------------------------------------------------------------------------------|
2             Validation | 0.9344 (22, 29,  7, 18) | 1.018 | 1.977 | 84.27 | 70.13 |#################################################################################| ^ (0.9%, 3.11, 2.1, 0%) 
setGhostBatches(4)
Change training batch size: 2048 -> 4096 (634 batches)
2 >>  4/20 <<   Training | 0.9316 (22, 28,  7, 19) | 1.036 | 2.114 | 84.57 | 69.25 |------------------------------------------------------------------------|
2             Validation | 0.9309 (22, 28,  7, 19) | 1.036 | 2.113 | 84.59 | 69.31 |#########################################################################| ^ (0.8%, 3.15, 2.3, 0%) 
2 >>  5/20 <<   Training | 0.9364 (20, 28,  8, 20) | 0.913 | 7.706 | 84.36 | 69.65 |----------------------------------------------------------------------------|
2             Validation | 0.9361 (20, 28,  8, 20) | 0.912 | 4.357 | 84.39 | 69.57 |###########################################################################| ^ (0.9%, 3.45, 0.7, 81%) 
2 >>  6/20 <<   Training | 0.9301 (22, 28,  7, 19) | 1.036 | 3.072 | 84.67 | 70.10 |---------------------------------------------------------------------------------|
2             Validation | 0.9301 (22, 28,  7, 19) | 1.035 | 2.167 | 84.67 | 70.03 |################################################################################| ^ (1.0%, 3.13, 1.7, 2%) 
setGhostBatches(1)
Change training batch size: 4096 -> 8192 (317 batches)
2 >>  7/20 <<   Training | 0.9286 (21, 28,  7, 19) | 1.007 | 4.445 | 84.76 | 70.95 |-----------------------------------------------------------------------------------------|
2             Validation | 0.9289 (21, 28,  7, 19) | 1.006 | 2.547 | 84.75 | 70.84 |########################################################################################| ^ (1.1%, 3.10, 1.6, 3%) 
2 >>  8/20 <<   Training | 0.9269 (22, 28,  7, 19) | 1.023 | 1.889 | 84.82 | 70.53 |-------------------------------------------------------------------------------------|
2             Validation | 0.9273 (22, 28,  7, 19) | 1.022 | 1.338 | 84.82 | 70.32 |###################################################################################| ^ (1.5%, 3.35, 1.5, 6%) 
2 >>  9/20 <<   Training | 0.9295 (21, 30,  7, 18) | 0.913 | 11.215 | 84.78 | 69.93 |-------------------------------------------------------------------------------|
2             Validation | 0.9300 (21, 30,  7, 18) | 0.912 | 7.000 | 84.77 | 69.75 |#############################################################################| ^ (1.4%, 3.98, 1.1, 27%) 
2 >> 10/20 <<   Training | 0.9266 (22, 27,  7, 19) | 1.054 | 3.401 | 84.84 | 70.23 |----------------------------------------------------------------------------------|
2             Validation | 0.9272 (22, 27,  7, 19) | 1.053 | 2.352 | 84.83 | 69.99 |###############################################################################| ^ (1.4%, 3.26, 2.3, 0%) 
setGhostBatches(0)
Change training batch size: 8192 -> 16384 (158 batches)
2 >> 11/20 <<   Training | 0.9286 (23, 29,  7, 17) | 1.070 | 7.191 | 84.84 | 70.57 |-------------------------------------------------------------------------------------|
2             Validation | 0.9298 (23, 29,  7, 17) | 1.070 | 4.772 | 84.82 | 70.30 |###################################################################################| ^ (1.6%, 3.37, 1.2, 18%) 
2 >> 12/20 <<   Training | 0.9258 (21, 28,  7, 19) | 0.959 | 5.006 | 84.91 | 70.49 |------------------------------------------------------------------------------------|
2             Validation | 0.9266 (21, 28,  7, 19) | 0.958 | 3.655 | 84.89 | 70.23 |##################################################################################| ^ (1.5%, 3.56, 1.6, 3%) 
2 >> 13/20 <<   Training | 0.9256 (22, 29,  7, 18) | 1.005 | 1.466 | 84.90 | 70.52 |-------------------------------------------------------------------------------------|
2             Validation | 0.9268 (22, 29,  6, 18) | 1.004 | 1.331 | 84.88 | 70.23 |##################################################################################| ^ (1.7%, 3.70, 1.4, 9%) 
2 >> 14/20 <<   Training | 0.9252 (21, 30,  7, 18) | 0.941 | 5.621 | 84.90 | 70.76 |---------------------------------------------------------------------------------------|
2             Validation | 0.9265 (21, 30,  7, 18) | 0.939 | 3.104 | 84.88 | 70.42 |####################################################################################| ^ (1.8%, 3.43, 1.3, 15%) 
2 >> 15/20 <<   Training | 0.9245 (22, 28,  7, 18) | 1.044 | 2.174 | 84.91 | 70.70 |---------------------------------------------------------------------------------------|
2             Validation | 0.9257 (22, 28,  7, 18) | 1.043 | 1.669 | 84.89 | 70.36 |###################################################################################| ^ (2.0%, 3.17, 1.4, 8%) 
Decay learning rate: 0.010000 -> 0.002500
2 >> 16/20 <<   Training | 0.9231 (22, 28,  7, 18) | 1.006 | 1.516 | 85.01 | 70.83 |----------------------------------------------------------------------------------------|
2             Validation | 0.9245 (22, 28,  7, 18) | 1.004 | 0.865 | 84.99 | 70.44 |####################################################################################| ^ (2.1%, 3.56, 1.3, 13%) 
Decay learning rate: 0.002500 -> 0.000625
2 >> 17/20 <<   Training | 0.9227 (22, 28,  7, 19) | 1.011 | 1.196 | 85.02 | 70.83 |----------------------------------------------------------------------------------------|
2             Validation | 0.9243 (22, 28,  7, 18) | 1.009 | 0.802 | 84.99 | 70.42 |####################################################################################| ^ (2.2%, 3.56, 1.5, 6%) 
Decay learning rate: 0.000625 -> 0.000156
2 >> 18/20 <<   Training | 0.9226 (22, 28,  7, 19) | 1.002 | 0.975 | 85.02 | 70.82 |----------------------------------------------------------------------------------------|
2             Validation | 0.9242 (22, 28,  7, 18) | 1.001 | 0.936 | 84.99 | 70.41 |####################################################################################| ^ (2.1%, 3.54, 1.4, 9%) 
Decay learning rate: 0.000156 -> 0.000039
2 >> 19/20 <<   Training | 0.9226 (22, 29,  7, 18) | 1.000 | 0.925 | 85.02 | 70.82 |----------------------------------------------------------------------------------------|
2             Validation | 0.9242 (22, 29,  7, 18) | 0.998 | 1.305 | 84.99 | 70.41 |####################################################################################| ^ (2.2%, 3.54, 1.4, 8%) 
Decay learning rate: 0.000039 -> 0.000010
2 >> 20/20 <<   Training | 0.9226 (22, 29,  7, 18) | 0.999 | 0.939 | 85.02 | 70.82 |----------------------------------------------------------------------------------------|
2             Validation | 0.9242 (22, 29,  7, 18) | 0.998 | 1.215 | 84.99 | 70.41 |####################################################################################| ^ (2.2%, 3.54, 1.4, 9%) * ZZ4b/nTupleAnalysis/pytorchModels/FvT_HCR+attention_12_np2076_lr0.01_epochs20_offset2_epoch20_before_finetuning.pkl
Run Finetuning
2 >> 20/20 <<   Training | 0.9226 (22, 29,  7, 18) | 0.997 | 1.025 | 85.02 | 70.82 |----------------------------------------------------------------------------------------|
2             Validation | 0.9242 (22, 29,  7, 18) | 0.996 | 1.215 | 84.99 | 70.41 |####################################################################################| ^ (2.2%, 3.55, 1.4, 10%) * ZZ4b/nTupleAnalysis/pytorchModels/FvT_HCR+attention_12_np2076_lr0.01_epochs20_offset2_epoch20.pkl
Decay learning rate: 0.000010 -> 0.000002
2 >> Epoch <<   Data Set |  Loss %(d4, d3, t4, t3) | Norm  | rchi2 | % AUC | % AUC | AUC Bar Graph ^ (ABC, Max Loss, chi2/bin, p-value) * Output Model
2 >>  1/20 <<   Training | 0.9485 (22, 30,  6, 17) | 0.994 | 3.371 | 83.47 | 68.24 |--------------------------------|
2             Validation | 0.9475 (22, 30,  6, 17) | 0.994 | 2.136 | 83.50 | 68.37 |#################################| ^ (1.0%, 2.95, 1.2, 22%) 
setGhostBatches(16)
Change training batch size: 1024 -> 2048 (1269 batches)
2 >>  2/20 <<   Training | 0.9410 (22, 26,  7, 20) | 0.985 | 9.603 | 84.03 | 68.27 |--------------------------------|
2             Validation | 0.9401 (22, 26,  7, 20) | 0.985 | 5.521 | 84.03 | 68.32 |#################################| ^ (0.8%, 3.29, 2.7, 0%) 
2 >>  3/20 <<   Training | 0.9354 (22, 29,  7, 18) | 1.019 | 3.118 | 84.24 | 69.98 |-------------------------------------------------|
2             Validation | 0.9344 (22, 29,  7, 18) | 1.018 | 1.977 | 84.27 | 70.13 |###################################################| ^ (0.9%, 3.11, 2.1, 0%) 
setGhostBatches(4)
Change training batch size: 2048 -> 4096 (634 batches)
2 >>  4/20 <<   Training | 0.9316 (22, 28,  7, 19) | 1.036 | 2.114 | 84.57 | 69.25 |------------------------------------------|
2             Validation | 0.9309 (22, 28,  7, 19) | 1.036 | 2.113 | 84.59 | 69.31 |###########################################| ^ (0.8%, 3.15, 2.3, 0%) 
2 >>  5/20 <<   Training | 0.9364 (20, 28,  8, 20) | 0.913 | 7.706 | 84.36 | 69.65 |----------------------------------------------|
2             Validation | 0.9361 (20, 28,  8, 20) | 0.912 | 4.357 | 84.39 | 69.57 |#############################################| ^ (0.9%, 3.45, 0.7, 81%) 
2 >>  6/20 <<   Training | 0.9301 (22, 28,  7, 19) | 1.036 | 3.072 | 84.67 | 70.10 |---------------------------------------------------|
2             Validation | 0.9301 (22, 28,  7, 19) | 1.035 | 2.167 | 84.67 | 70.03 |##################################################| ^ (1.0%, 3.13, 1.7, 2%) 
setGhostBatches(1)
Change training batch size: 4096 -> 8192 (317 batches)
2 >>  7/20 <<   Training | 0.9286 (21, 28,  7, 19) | 1.007 | 4.445 | 84.76 | 70.95 |-----------------------------------------------------------|
2             Validation | 0.9289 (21, 28,  7, 19) | 1.006 | 2.547 | 84.75 | 70.84 |##########################################################| ^ (1.1%, 3.10, 1.6, 3%) 
2 >>  8/20 <<   Training | 0.9269 (22, 28,  7, 19) | 1.023 | 1.889 | 84.82 | 70.53 |-------------------------------------------------------|
2             Validation | 0.9273 (22, 28,  7, 19) | 1.022 | 1.338 | 84.82 | 70.32 |#####################################################| ^ (1.5%, 3.35, 1.5, 6%) 
2 >>  9/20 <<   Training | 0.9295 (21, 30,  7, 18) | 0.913 | 11.215 | 84.78 | 69.93 |-------------------------------------------------|
2             Validation | 0.9300 (21, 30,  7, 18) | 0.912 | 7.000 | 84.77 | 69.75 |###############################################| ^ (1.4%, 3.98, 1.1, 27%) 
2 >> 10/20 <<   Training | 0.9266 (22, 27,  7, 19) | 1.054 | 3.401 | 84.84 | 70.23 |----------------------------------------------------|
2             Validation | 0.9272 (22, 27,  7, 19) | 1.053 | 2.352 | 84.83 | 69.99 |#################################################| ^ (1.4%, 3.26, 2.3, 0%) 
setGhostBatches(0)
Change training batch size: 8192 -> 16384 (158 batches)
2 >> 11/20 <<   Training | 0.9286 (23, 29,  7, 17) | 1.070 | 7.191 | 84.84 | 70.57 |-------------------------------------------------------|
2             Validation | 0.9298 (23, 29,  7, 17) | 1.070 | 4.772 | 84.82 | 70.30 |#####################################################| ^ (1.6%, 3.37, 1.2, 18%) 
2 >> 12/20 <<   Training | 0.9258 (21, 28,  7, 19) | 0.959 | 5.006 | 84.91 | 70.49 |------------------------------------------------------|
2             Validation | 0.9266 (21, 28,  7, 19) | 0.958 | 3.655 | 84.89 | 70.23 |####################################################| ^ (1.5%, 3.56, 1.6, 3%) 
2 >> 13/20 <<   Training | 0.9256 (22, 29,  7, 18) | 1.005 | 1.466 | 84.90 | 70.52 |-------------------------------------------------------|
2             Validation | 0.9268 (22, 29,  6, 18) | 1.004 | 1.331 | 84.88 | 70.23 |####################################################| ^ (1.7%, 3.70, 1.4, 9%) 
2 >> 14/20 <<   Training | 0.9252 (21, 30,  7, 18) | 0.941 | 5.621 | 84.90 | 70.76 |---------------------------------------------------------|
2             Validation | 0.9265 (21, 30,  7, 18) | 0.939 | 3.104 | 84.88 | 70.42 |######################################################| ^ (1.8%, 3.43, 1.3, 15%) 
2 >> 15/20 <<   Training | 0.9245 (22, 28,  7, 18) | 1.044 | 2.174 | 84.91 | 70.70 |---------------------------------------------------------|
2             Validation | 0.9257 (22, 28,  7, 18) | 1.043 | 1.669 | 84.89 | 70.36 |#####################################################| ^ (2.0%, 3.17, 1.4, 8%) 
Decay learning rate: 0.010000 -> 0.002500
2 >> 16/20 <<   Training | 0.9231 (22, 28,  7, 18) | 1.006 | 1.516 | 85.01 | 70.83 |----------------------------------------------------------|
2             Validation | 0.9245 (22, 28,  7, 18) | 1.004 | 0.865 | 84.99 | 70.44 |######################################################| ^ (2.1%, 3.56, 1.3, 13%) 
Decay learning rate: 0.002500 -> 0.000625
2 >> 17/20 <<   Training | 0.9227 (22, 28,  7, 19) | 1.011 | 1.196 | 85.02 | 70.83 |----------------------------------------------------------|
2             Validation | 0.9243 (22, 28,  7, 18) | 1.009 | 0.802 | 84.99 | 70.42 |######################################################| ^ (2.2%, 3.56, 1.5, 6%) 
Decay learning rate: 0.000625 -> 0.000156
2 >> 18/20 <<   Training | 0.9226 (22, 28,  7, 19) | 1.002 | 0.975 | 85.02 | 70.82 |----------------------------------------------------------|
2             Validation | 0.9242 (22, 28,  7, 18) | 1.001 | 0.936 | 84.99 | 70.41 |######################################################| ^ (2.1%, 3.54, 1.4, 9%) 
Decay learning rate: 0.000156 -> 0.000039
2 >> 19/20 <<   Training | 0.9226 (22, 29,  7, 18) | 1.000 | 0.925 | 85.02 | 70.82 |----------------------------------------------------------|
2             Validation | 0.9242 (22, 29,  7, 18) | 0.998 | 1.305 | 84.99 | 70.41 |######################################################| ^ (2.2%, 3.54, 1.4, 8%) 
Decay learning rate: 0.000039 -> 0.000010
2 >> 20/20 <<   Training | 0.9226 (22, 29,  7, 18) | 0.999 | 0.939 | 85.02 | 70.82 |----------------------------------------------------------|
2             Validation | 0.9242 (22, 29,  7, 18) | 0.998 | 1.215 | 84.99 | 70.41 |######################################################| ^ (2.2%, 3.54, 1.4, 9%) * ZZ4b/nTupleAnalysis/pytorchModels/FvT_HCR+attention_12_np2076_lr0.01_epochs20_offset2_epoch20_before_finetuning.pkl
Run Finetuning
2 >> 20/20 <<   Training | 0.9226 (22, 29,  7, 18) | 0.997 | 1.025 | 85.02 | 70.82 |----------------------------------------------------------|
2             Validation | 0.9242 (22, 29,  7, 18) | 0.996 | 1.215 | 84.99 | 70.41 |######################################################| ^ (2.2%, 3.55, 1.4, 10%) * ZZ4b/nTupleAnalysis/pytorchModels/FvT_HCR+attention_12_np2076_lr0.01_epochs20_offset2_epoch20.pkl
Decay learning rate: 0.000010 -> 0.000002
