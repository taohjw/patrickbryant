1 >> Epoch <<   Data Set |  Loss %(d4, d3, t4, t3) | Norm  | r_max | % AUC | % AUC | AUC Bar Graph ^ (ABC, Max Loss, chi2/bin, p-value) * Output Model
1 >>  1/20 <<   Training | 0.8986 (35, 37,  8, 20) | 0.943 |   7.1 | 81.65 | 64.67 |--------------------------|
1             Validation | 0.8986 (35, 37,  8, 20) | 0.942 |   7.4 | 81.63 | 64.62 |##########################| ^ (0.9%, 2.12, 1.1, 30%) 
setGhostBatches(8)
Increase training batch size: 1024 -> 2048 (1210 batches)
Decay learning rate: 0.010000 -> 0.005000
1 >>  2/20 <<   Training | 0.9191 (31, 37,  9, 23) | 0.838 |   8.8 | 81.76 | 65.78 |-------------------------------------|
1             Validation | 0.9194 (31, 37,  9, 23) | 0.837 |   9.0 | 81.69 | 65.73 |#####################################| ^ (0.9%, 2.75, 1.1, 27%) 
1 >>  3/20 <<   Training | 0.8818 (35, 39,  8, 19) | 0.893 |   7.3 | 83.16 | 65.70 |-------------------------------------|
1             Validation | 0.8822 (35, 39,  8, 19) | 0.892 |   7.1 | 83.12 | 65.61 |####################################| ^ (1.0%, 2.89, 1.5, 5%) 
setGhostBatches(1)
Increase training batch size: 2048 -> 4096 (605 batches)
Decay learning rate: 0.005000 -> 0.002500
1 >>  4/20 <<   Training | 0.8780 (35, 38,  8, 19) | 0.905 |   8.6 | 83.51 | 66.22 |------------------------------------------|
1             Validation | 0.8788 (35, 38,  8, 19) | 0.905 |   8.4 | 83.43 | 66.09 |########################################| ^ (1.0%, 2.90, 1.4, 10%) 
1 >>  5/20 <<   Training | 0.8779 (36, 38,  8, 19) | 0.935 |   8.2 | 83.38 | 66.16 |-----------------------------------------|
1             Validation | 0.8788 (36, 38,  8, 19) | 0.935 |   7.5 | 83.30 | 66.04 |########################################| ^ (1.1%, 2.79, 0.9, 49%) 
1 >>  6/20 <<   Training | 0.8729 (38, 37,  7, 18) | 0.969 |  11.5 | 83.70 | 66.24 |------------------------------------------|
1             Validation | 0.8740 (38, 37,  7, 18) | 0.969 |  11.1 | 83.64 | 66.08 |########################################| ^ (1.2%, 2.95, 1.2, 20%) 
setGhostBatches(0)
Increase training batch size: 4096 -> 8192 (302 batches)
Decay learning rate: 0.002500 -> 0.001250
1 >>  7/20 <<   Training | 0.8615 (39, 39,  6, 16) | 1.012 | -13.9 | 84.93 | 66.31 |-------------------------------------------|
1             Validation | 0.8622 (39, 39,  6, 16) | 1.011 | -12.6 | 84.92 | 66.17 |#########################################| ^ (1.2%, 3.22, 2.5, 0%) 
1 >>  8/20 <<   Training | 0.8611 (39, 38,  7, 16) | 1.011 | -12.9 | 84.98 | 66.32 |-------------------------------------------|
1             Validation | 0.8621 (39, 38,  7, 16) | 1.010 | -12.8 | 84.96 | 66.14 |#########################################| ^ (1.4%, 3.37, 1.9, 0%) 
1 >>  9/20 <<   Training | 0.8606 (39, 39,  6, 16) | 0.994 | -12.1 | 85.03 | 66.42 |--------------------------------------------|
1             Validation | 0.8614 (39, 39,  7, 16) | 0.993 | -12.3 | 85.02 | 66.24 |##########################################| ^ (1.4%, 3.09, 1.4, 8%) 
1 >> 10/20 <<   Training | 0.8607 (37, 40,  6, 16) | 0.951 | -13.6 | 85.06 | 66.38 |-------------------------------------------|
1             Validation | 0.8614 (37, 40,  6, 16) | 0.950 | -13.5 | 85.06 | 66.22 |##########################################| ^ (1.2%, 3.09, 1.7, 2%) 
Increase training batch size: 8192 -> 16384 (151 batches)
Decay learning rate: 0.001250 -> 0.000625
1 >> 11/20 <<   Training | 0.8600 (39, 38,  6, 16) | 1.012 | -14.6 | 85.11 | 66.51 |---------------------------------------------|
1             Validation | 0.8608 (39, 38,  6, 16) | 1.012 | -14.6 | 85.10 | 66.33 |###########################################| ^ (1.3%, 3.22, 1.2, 20%) 
1 >> 12/20 <<   Training | 0.8599 (39, 39,  6, 16) | 0.993 | -15.8 | 85.12 | 66.49 |--------------------------------------------|
1             Validation | 0.8608 (39, 39,  6, 16) | 0.992 | -15.5 | 85.11 | 66.31 |###########################################| ^ (1.3%, 3.25, 2.2, 0%) 
1 >> 13/20 <<   Training | 0.8598 (39, 39,  6, 16) | 1.013 | -15.4 | 85.12 | 66.50 |---------------------------------------------|
1             Validation | 0.8607 (39, 38,  6, 16) | 1.012 | -15.4 | 85.11 | 66.32 |###########################################| ^ (1.4%, 3.15, 1.7, 2%) 
1 >> 14/20 <<   Training | 0.8597 (39, 39,  6, 16) | 0.997 | -14.4 | 85.13 | 66.47 |--------------------------------------------|
1             Validation | 0.8606 (39, 39,  6, 16) | 0.997 | -15.0 | 85.12 | 66.29 |##########################################| ^ (1.4%, 3.19, 1.8, 1%) 
1 >> 15/20 <<   Training | 0.8597 (38, 39,  6, 16) | 0.987 | -17.3 | 85.14 | 66.54 |---------------------------------------------|
1             Validation | 0.8606 (38, 39,  6, 16) | 0.986 | -18.3 | 85.13 | 66.35 |###########################################| ^ (1.3%, 3.18, 2.2, 0%) 
Decay learning rate: 0.000625 -> 0.000313
1 >> 16/20 <<   Training | 0.8596 (39, 39,  6, 16) | 0.990 | -16.5 | 85.14 | 66.52 |---------------------------------------------|
1             Validation | 0.8605 (39, 39,  6, 16) | 0.990 | -16.3 | 85.14 | 66.33 |###########################################| ^ (1.4%, 3.19, 2.3, 0%) 
Decay learning rate: 0.000313 -> 0.000156
1 >> 17/20 <<   Training | 0.8595 (39, 39,  6, 16) | 1.000 | -16.2 | 85.15 | 66.51 |---------------------------------------------|
1             Validation | 0.8605 (39, 39,  6, 16) | 0.999 | -16.5 | 85.14 | 66.31 |###########################################| ^ (1.4%, 3.19, 2.2, 0%) 
Decay learning rate: 0.000156 -> 0.000078
1 >> 18/20 <<   Training | 0.8595 (39, 39,  6, 16) | 0.993 | -15.6 | 85.15 | 66.51 |---------------------------------------------|
1             Validation | 0.8604 (39, 39,  6, 16) | 0.992 | -15.9 | 85.14 | 66.32 |###########################################| ^ (1.4%, 3.18, 1.8, 1%) 
Decay learning rate: 0.000078 -> 0.000039
1 >> 19/20 <<   Training | 0.8595 (39, 39,  6, 16) | 0.997 | -15.4 | 85.15 | 66.51 |---------------------------------------------|
1             Validation | 0.8604 (39, 39,  6, 16) | 0.996 | -15.8 | 85.14 | 66.32 |###########################################| ^ (1.4%, 3.19, 1.7, 2%) 
Decay learning rate: 0.000039 -> 0.000020
1 >> 20/20 <<   Training | 0.8595 (39, 39,  6, 16) | 1.001 | -15.6 | 85.15 | 66.51 |---------------------------------------------|
1             Validation | 0.8604 (39, 39,  6, 16) | 1.000 | -16.1 | 85.14 | 66.31 |###########################################| ^ (1.4%, 3.20, 1.8, 1%) * ZZ4b/nTupleAnalysis/pytorchModels/FvT_HCR+attention_14_np2840_lr0.01_epochs20_offset1_epoch20.pkl
Decay learning rate: 0.000020 -> 0.000010
