2 >> Epoch <<   Data Set |  Loss %(d4, d3, t4, t3) | Norm  | r_max | % AUC | % AUC | AUC Bar Graph ^ (ABC, Max Loss, chi2/bin, p-value) * Output Model
2 >>  1/20 <<   Training | 0.8885 (39, 38,  6, 17) | 1.051 |  -9.5 | 82.16 | 63.94 |-------------------|
2             Validation | 0.8883 (39, 38,  6, 17) | 1.044 |  -6.7 | 82.19 | 63.88 |##################| ^ (0.9%, 3.91, 1.5, 5%) 
setGhostBatches(8)
Increase training batch size: 1024 -> 2048 (1210 batches)
Decay learning rate: 0.010000 -> 0.005000
2 >>  2/20 <<   Training | 0.8760 (38, 39,  7, 16) | 0.926 |  19.1 | 83.30 | 65.96 |---------------------------------------|
2             Validation | 0.8762 (38, 39,  7, 17) | 0.920 |  17.3 | 83.30 | 65.94 |#######################################| ^ (0.7%, 2.59, 1.4, 7%) 
2 >>  3/20 <<   Training | 0.8766 (37, 39,  7, 17) | 0.927 |  13.9 | 83.22 | 66.01 |----------------------------------------|
2             Validation | 0.8775 (37, 39,  6, 17) | 0.922 |  12.7 | 83.19 | 65.85 |######################################| ^ (1.1%, 3.78, 1.4, 10%) 
setGhostBatches(1)
Increase training batch size: 2048 -> 4096 (605 batches)
Decay learning rate: 0.005000 -> 0.002500
2 >>  4/20 <<   Training | 0.8692 (38, 38,  6, 17) | 0.993 |  10.0 | 83.67 | 66.19 |-----------------------------------------|
2             Validation | 0.8701 (38, 38,  6, 17) | 0.987 |  10.1 | 83.64 | 66.04 |########################################| ^ (1.1%, 2.94, 1.5, 6%) 
2 >>  5/20 <<   Training | 0.8686 (39, 38,  6, 16) | 1.022 |   9.1 | 83.77 | 66.19 |-----------------------------------------|
2             Validation | 0.8691 (39, 38,  6, 16) | 1.016 |   8.7 | 83.75 | 66.05 |########################################| ^ (1.0%, 3.01, 1.4, 9%) 
2 >>  6/20 <<   Training | 0.8702 (37, 40,  6, 16) | 0.931 | -12.2 | 83.52 | 66.15 |-----------------------------------------|
2             Validation | 0.8711 (37, 40,  6, 16) | 0.926 | -15.2 | 83.49 | 66.00 |########################################| ^ (1.0%, 3.25, 1.3, 14%) 
setGhostBatches(0)
Increase training batch size: 4096 -> 8192 (302 batches)
Decay learning rate: 0.002500 -> 0.001250
2 >>  7/20 <<   Training | 0.8622 (38, 39,  7, 16) | 0.977 |  10.7 | 84.75 | 66.42 |--------------------------------------------|
2             Validation | 0.8635 (38, 39,  7, 16) | 0.970 | -17.4 | 84.69 | 66.17 |#########################################| ^ (1.5%, 3.54, 1.0, 35%) 
2 >>  8/20 <<   Training | 0.8620 (39, 38,  7, 16) | 1.001 | -15.5 | 84.80 | 66.44 |--------------------------------------------|
2             Validation | 0.8633 (38, 38,  7, 16) | 0.995 | -18.0 | 84.74 | 66.19 |#########################################| ^ (1.5%, 3.58, 1.5, 4%) 
2 >>  9/20 <<   Training | 0.8617 (38, 39,  7, 16) | 0.970 | -20.0 | 84.85 | 66.43 |--------------------------------------------|
2             Validation | 0.8632 (38, 39,  6, 16) | 0.964 | -20.0 | 84.79 | 66.18 |#########################################| ^ (1.5%, 3.65, 1.3, 12%) 
2 >> 10/20 <<   Training | 0.8611 (39, 39,  7, 16) | 1.002 | -20.0 | 84.91 | 66.44 |--------------------------------------------|
2             Validation | 0.8626 (39, 39,  6, 16) | 0.996 | -20.0 | 84.84 | 66.16 |#########################################| ^ (1.7%, 3.48, 1.8, 1%) 
Increase training batch size: 8192 -> 16384 (151 batches)
Decay learning rate: 0.001250 -> 0.000625
2 >> 11/20 <<   Training | 0.8609 (39, 38,  6, 16) | 1.024 | -20.0 | 84.93 | 66.48 |--------------------------------------------|
2             Validation | 0.8625 (39, 38,  6, 16) | 1.018 | -20.0 | 84.87 | 66.19 |#########################################| ^ (1.8%, 3.57, 1.7, 2%) 
2 >> 12/20 <<   Training | 0.8608 (39, 38,  6, 16) | 1.009 | -20.0 | 84.94 | 66.51 |---------------------------------------------|
2             Validation | 0.8624 (39, 38,  6, 16) | 1.003 | -20.0 | 84.88 | 66.22 |##########################################| ^ (1.8%, 3.60, 2.3, 0%) 
2 >> 13/20 <<   Training | 0.8607 (39, 39,  7, 16) | 0.993 | -20.0 | 84.96 | 66.48 |--------------------------------------------|
2             Validation | 0.8623 (39, 39,  6, 16) | 0.986 | -20.0 | 84.89 | 66.18 |#########################################| ^ (1.8%, 3.60, 1.8, 1%) 
2 >> 14/20 <<   Training | 0.8607 (38, 39,  6, 16) | 0.986 | -20.0 | 84.96 | 66.43 |--------------------------------------------|
2             Validation | 0.8623 (38, 39,  6, 16) | 0.979 | -20.0 | 84.90 | 66.15 |#########################################| ^ (1.8%, 3.55, 2.2, 0%) 
2 >> 15/20 <<   Training | 0.8606 (39, 39,  6, 16) | 1.008 | -20.0 | 84.98 | 66.48 |--------------------------------------------|
2             Validation | 0.8622 (39, 39,  6, 16) | 1.001 | -20.0 | 84.91 | 66.18 |#########################################| ^ (1.9%, 3.69, 2.3, 0%) 
Decay learning rate: 0.000625 -> 0.000313
2 >> 16/20 <<   Training | 0.8605 (38, 39,  6, 16) | 0.990 | -20.0 | 84.98 | 66.50 |---------------------------------------------|
2             Validation | 0.8621 (38, 39,  6, 16) | 0.983 | -20.0 | 84.92 | 66.20 |#########################################| ^ (1.9%, 3.61, 1.8, 1%) 
Decay learning rate: 0.000313 -> 0.000156
2 >> 17/20 <<   Training | 0.8604 (39, 39,  7, 16) | 1.006 | -20.0 | 84.99 | 66.49 |--------------------------------------------|
2             Validation | 0.8621 (39, 39,  6, 16) | 0.999 | -20.0 | 84.92 | 66.18 |#########################################| ^ (1.9%, 3.65, 2.1, 0%) 
Decay learning rate: 0.000156 -> 0.000078
2 >> 18/20 <<   Training | 0.8604 (39, 39,  6, 16) | 0.996 | -20.0 | 84.99 | 66.50 |---------------------------------------------|
2             Validation | 0.8621 (39, 39,  6, 16) | 0.989 | -20.0 | 84.92 | 66.20 |#########################################| ^ (1.9%, 3.66, 1.9, 1%) 
Decay learning rate: 0.000078 -> 0.000039
2 >> 19/20 <<   Training | 0.8604 (39, 39,  6, 16) | 1.002 | -20.0 | 84.99 | 66.50 |---------------------------------------------|
2             Validation | 0.8621 (39, 39,  6, 16) | 0.995 | -20.0 | 84.92 | 66.20 |#########################################| ^ (1.9%, 3.66, 2.2, 0%) 
Decay learning rate: 0.000039 -> 0.000020
2 >> 20/20 <<   Training | 0.8604 (39, 39,  6, 16) | 0.999 | -20.0 | 84.99 | 66.51 |---------------------------------------------|
2             Validation | 0.8621 (39, 39,  6, 16) | 0.992 | -20.0 | 84.92 | 66.20 |#########################################| ^ (1.9%, 3.66, 2.1, 0%) * ZZ4b/nTupleAnalysis/pytorchModels/FvT_HCR+attention_14_np2840_lr0.01_epochs20_offset2_epoch20.pkl
Decay learning rate: 0.000020 -> 0.000010
