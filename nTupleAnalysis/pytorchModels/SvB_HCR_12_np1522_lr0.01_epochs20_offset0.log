0 >> Epoch <<   Data Set |  Loss %(zz, zh, tt, mj) | σ     | σ(SR) | % AUC | % AUC | AUC Bar Graph ^ (ABC, Max Loss, chi2/bin, p-value) * Output Model
0 >>  1/20 <<   Training | 0.6828 (26, 29, 10, 35) | 0.655 | 0.761 | 87.48 | 86.07 |--------------------|
0             Validation | 0.6877 (27, 29, 10, 35) | 0.653 | 0.759 | 86.94 | 85.90 |##################| ^ (0.5%, 10.30, 2.1, 0%) 
setGhostBatches(16)
Change training batch size: 1024 -> 2048 (996 batches)
0 >>  2/20 <<   Training | 0.6682 (26, 30, 11, 34) | 0.705 | 0.816 | 88.04 | 86.52 |-------------------------|
0             Validation | 0.6729 (27, 30, 11, 33) | 0.690 | 0.799 | 87.58 | 86.37 |#######################| ^ (0.5%, 13.85, 2.1, 0%) 
0 >>  3/20 <<   Training | 0.6605 (26, 29, 11, 35) | 0.714 | 0.828 | 88.68 | 86.85 |----------------------------|
0             Validation | 0.6669 (27, 28, 11, 34) | 0.723 | 0.838 | 88.16 | 86.61 |##########################| ^ (0.7%, 11.53, 2.7, 0%) 
setGhostBatches(4)
Change training batch size: 2048 -> 4096 (498 batches)
0 >>  4/20 <<   Training | 0.6589 (29, 31, 11, 30) | 0.729 | 0.845 | 88.75 | 86.90 |-----------------------------|
0             Validation | 0.6682 (30, 31, 11, 29) | 0.736 | 0.854 | 88.06 | 86.58 |#########################| ^ (0.9%, 14.41, 2.8, 0%) 
0 >>  5/20 <<   Training | 0.6558 (27, 32, 11, 31) | 0.736 | 0.854 | 88.91 | 87.04 |------------------------------|
0             Validation | 0.6632 (28, 32, 11, 30) | 0.732 | 0.847 | 88.32 | 86.77 |###########################| ^ (0.7%, 11.08, 3.0, 0%) 
0 >>  6/20 <<   Training | 0.6598 (25, 30, 11, 35) | 0.673 | 0.780 | 88.80 | 86.83 |----------------------------|
0             Validation | 0.6682 (26, 30, 11, 34) | 0.671 | 0.778 | 88.11 | 86.56 |#########################| ^ (0.8%, 13.96, 2.8, 0%) 
setGhostBatches(1)
Change training batch size: 4096 -> 8192 (249 batches)
0 >>  7/20 <<   Training | 0.6542 (28, 30, 11, 31) | 0.748 | 0.867 | 88.77 | 87.09 |------------------------------|
0             Validation | 0.6633 (30, 30, 11, 30) | 0.741 | 0.859 | 88.11 | 86.76 |###########################| ^ (0.9%, 12.80, 3.3, 0%) 
0 >>  8/20 <<   Training | 0.6522 (26, 29, 11, 34) | 0.734 | 0.848 | 89.04 | 87.15 |-------------------------------|
0             Validation | 0.6601 (27, 29, 11, 34) | 0.730 | 0.847 | 88.32 | 86.92 |#############################| ^ (0.6%, 13.89, 2.0, 0%) 
0 >>  9/20 <<   Training | 0.6522 (24, 31, 11, 34) | 0.745 | 0.862 | 89.00 | 87.21 |--------------------------------|
0             Validation | 0.6604 (26, 31, 11, 34) | 0.739 | 0.858 | 88.35 | 86.91 |#############################| ^ (0.8%, 13.00, 2.4, 0%) 
0 >> 10/20 <<   Training | 0.6521 (27, 30, 11, 33) | 0.739 | 0.857 | 88.99 | 87.19 |-------------------------------|
0             Validation | 0.6608 (28, 30, 11, 32) | 0.724 | 0.839 | 88.24 | 86.93 |#############################| ^ (0.7%, 14.71, 2.3, 0%) 
setGhostBatches(0)
Change training batch size: 8192 -> 16384 (124 batches)
0 >> 11/20 <<   Training | 0.6490 (26, 30, 11, 34) | 0.752 | 0.871 | 89.14 | 87.28 |--------------------------------|
0             Validation | 0.6580 (28, 29, 11, 33) | 0.746 | 0.865 | 88.40 | 86.99 |#############################| ^ (0.8%, 15.29, 2.8, 0%) 
0 >> 12/20 <<   Training | 0.6492 (28, 29, 11, 32) | 0.761 | 0.880 | 89.06 | 87.30 |---------------------------------|
0             Validation | 0.6581 (29, 29, 11, 32) | 0.752 | 0.870 | 88.36 | 87.03 |##############################| ^ (0.7%, 14.27, 2.2, 0%) 
0 >> 13/20 <<   Training | 0.6503 (27, 28, 11, 35) | 0.755 | 0.873 | 89.08 | 87.29 |--------------------------------|
0             Validation | 0.6594 (28, 27, 11, 35) | 0.743 | 0.861 | 88.35 | 87.01 |##############################| ^ (0.8%, 14.62, 2.1, 0%) 
0 >> 14/20 <<   Training | 0.6507 (26, 28, 11, 36) | 0.745 | 0.863 | 89.18 | 87.26 |--------------------------------|
0             Validation | 0.6598 (27, 28, 10, 35) | 0.746 | 0.866 | 88.46 | 86.95 |#############################| ^ (0.9%, 12.81, 2.9, 0%) 
0 >> 15/20 <<   Training | 0.6512 (28, 29, 11, 32) | 0.734 | 0.850 | 88.98 | 87.22 |--------------------------------|
0             Validation | 0.6608 (30, 29, 11, 31) | 0.730 | 0.848 | 88.27 | 86.92 |#############################| ^ (0.8%, 14.48, 2.4, 0%) 
Decay learning rate: 0.010000 -> 0.002500
0 >> 16/20 <<   Training | 0.6465 (25, 30, 11, 34) | 0.764 | 0.883 | 89.31 | 87.39 |---------------------------------|
0             Validation | 0.6553 (26, 30, 11, 33) | 0.753 | 0.872 | 88.60 | 87.11 |###############################| ^ (0.8%, 14.26, 3.0, 0%) 
Decay learning rate: 0.002500 -> 0.000625
0 >> 17/20 <<   Training | 0.6455 (27, 30, 11, 33) | 0.764 | 0.883 | 89.26 | 87.42 |----------------------------------|
0             Validation | 0.6550 (28, 30, 11, 32) | 0.752 | 0.871 | 88.53 | 87.11 |###############################| ^ (0.9%, 14.18, 2.3, 0%) 
Decay learning rate: 0.000625 -> 0.000156
0 >> 18/20 <<   Training | 0.6454 (26, 30, 11, 33) | 0.762 | 0.881 | 89.28 | 87.42 |----------------------------------|
0             Validation | 0.6549 (28, 30, 11, 32) | 0.752 | 0.872 | 88.55 | 87.11 |###############################| ^ (0.9%, 14.19, 2.3, 0%) 
Decay learning rate: 0.000156 -> 0.000039
0 >> 19/20 <<   Training | 0.6454 (27, 30, 11, 33) | 0.762 | 0.882 | 89.28 | 87.42 |----------------------------------|
0             Validation | 0.6549 (28, 30, 11, 32) | 0.753 | 0.872 | 88.54 | 87.11 |###############################| ^ (0.9%, 14.22, 2.3, 0%) 
Decay learning rate: 0.000039 -> 0.000010
0 >> 20/20 <<   Training | 0.6454 (27, 30, 11, 33) | 0.762 | 0.882 | 89.28 | 87.42 |----------------------------------|
0             Validation | 0.6550 (28, 30, 11, 32) | 0.753 | 0.873 | 88.54 | 87.11 |###############################| ^ (0.9%, 14.22, 2.3, 0%) * ZZ4b/nTupleAnalysis/pytorchModels/SvB_HCR_12_np1522_lr0.01_epochs20_offset0_epoch20.pkl
Decay learning rate: 0.000010 -> 0.000002
